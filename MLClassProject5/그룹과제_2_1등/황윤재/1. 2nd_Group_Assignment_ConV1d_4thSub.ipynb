{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93b41229599509f643f1c1df3b86b3f79b66666f"
   },
   "source": [
    "## This model has the following characteristics:\n",
    "* No feature engineering\n",
    "* Applying bidirectional Conv1D to raw transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run import_modules.py\n",
    "%matplotlib inline\n",
    "\n",
    "# Tensorflow warning off\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.constraints import max_norm\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import *\n",
    "\n",
    "##tf.random.set_seed(1)\n",
    "from keras import backend as K\n",
    "from keras.layers import * \n",
    "from keras.models import * \n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.vis_utils import * #model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd7e3527fd56e5b5855c6846ca226f5f860f725b"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "794123064b09797f51add356a676fb6a7aed015d",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>store_nm</th>\n",
       "      <th>goods_id</th>\n",
       "      <th>gds_grp_nm</th>\n",
       "      <th>gds_grp_mclas_nm</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395552</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>85150</td>\n",
       "      <td>포숑</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395553</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>657121</td>\n",
       "      <td>서양델리</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395554</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>85150</td>\n",
       "      <td>밥류</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395555</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>50109</td>\n",
       "      <td>일반가공식품</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>178750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395556</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>85150</td>\n",
       "      <td>패밀리레스토랑</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395557</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>50105</td>\n",
       "      <td>일반가공식품</td>\n",
       "      <td>가공식품</td>\n",
       "      <td>209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395558</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>50109</td>\n",
       "      <td>상품군미지정</td>\n",
       "      <td>기타</td>\n",
       "      <td>7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395559</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>50105</td>\n",
       "      <td>햄</td>\n",
       "      <td>축산가공</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395560</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-01-12 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>50105</td>\n",
       "      <td>상품군미지정</td>\n",
       "      <td>기타</td>\n",
       "      <td>9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395561</th>\n",
       "      <td>5981</td>\n",
       "      <td>2007-03-16 00:00:00</td>\n",
       "      <td>영등포점</td>\n",
       "      <td>77198</td>\n",
       "      <td>수입식품</td>\n",
       "      <td>차/커피</td>\n",
       "      <td>174800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id            tran_date store_nm  goods_id gds_grp_nm  \\\n",
       "395552     5981  2007-01-12 00:00:00     영등포점     85150         포숑   \n",
       "395553     5981  2007-01-12 00:00:00     영등포점    657121       서양델리   \n",
       "395554     5981  2007-01-12 00:00:00     영등포점     85150         밥류   \n",
       "395555     5981  2007-01-12 00:00:00     영등포점     50109     일반가공식품   \n",
       "395556     5981  2007-01-12 00:00:00     영등포점     85150    패밀리레스토랑   \n",
       "395557     5981  2007-01-12 00:00:00     영등포점     50105     일반가공식품   \n",
       "395558     5981  2007-01-12 00:00:00     영등포점     50109     상품군미지정   \n",
       "395559     5981  2007-01-12 00:00:00     영등포점     50105          햄   \n",
       "395560     5981  2007-01-12 00:00:00     영등포점     50105     상품군미지정   \n",
       "395561     5981  2007-03-16 00:00:00     영등포점     77198       수입식품   \n",
       "\n",
       "       gds_grp_mclas_nm  amount  \n",
       "395552             가공식품   18000  \n",
       "395553             가공식품   11000  \n",
       "395554             가공식품    3000  \n",
       "395555             가공식품  178750  \n",
       "395556             가공식품    3000  \n",
       "395557             가공식품  209000  \n",
       "395558               기타    7150  \n",
       "395559             축산가공    9500  \n",
       "395560               기타    9500  \n",
       "395561             차/커피  174800  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "df = pd.concat([df_train,df_test],ignore_index=True)\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fdb273f73bbee0a8f11b33be46446b6825e9b6a"
   },
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "1d8108fcba83b0743ebefafd65d491e79fd1c4bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 200), (2482, 200))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 2000 # 324\n",
    "max_len = 200\n",
    "emb_dim = 64\n",
    "\n",
    "df.goods_id = df.goods_id.astype(str)\n",
    "# Converts a \"gds_grp_nm\" to a sequence of indexes in a fixed-size hashing space\n",
    "train_test = df.groupby('cust_id')['gds_grp_nm'].apply(lambda x: [one_hot(i, max_features)[0] for i in x]).values\n",
    "X_train = train_test[:3500]\n",
    "X_test = train_test[3500:]\n",
    "#X_train = df_train.groupby('cust_id')['goods_id'].apply(lambda x: [one_hot(i, max_features)[0] for i in x]).values\n",
    "#X_test = df_test.groupby('cust_id')['goods_id'].apply(lambda x: [one_hot(i, max_features)[0] for i in x]).values\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    x = np.unique(X_train[i])\n",
    "    y = np.array([])\n",
    "    for j in range(5):\n",
    "        y = np.append(y, np.random.choice(x, len(x), replace=False))\n",
    "    X_train[i] = y    \n",
    "\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    x = np.unique(X_test[i])\n",
    "    y = np.array([])\n",
    "    for j in range(5):\n",
    "        y = np.append(y, np.random.choice(x, len(x), replace=False))\n",
    "    X_test[i] = y    \n",
    "  \n",
    "    \n",
    "# Pads sequences to the same length\n",
    "X_train_conv1d = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test_conv1d = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "X_train_conv1d.shape, X_test_conv1d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "756511749ed6b1dcd34e791c15f041d4e47f9df4"
   },
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### 1st try (전반적인 아키텍쳐의 파라미터 조정 시도(패딩, activation 함수) -> 성능이 다 더 떨어짐, \n",
    "  ### Flattening 후 단순 DNN과 연결 -> 성능 떨어짐)  Dropout 값만 조정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "forward (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_94 (Embedding)     (None, 200, 64)           128000    \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 200, 32)           14368     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_188 (Conv1D)          (None, 40, 32)            7200      \n",
      "_________________________________________________________________\n",
      "flatten_92 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 8)                 10248     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 159,825\n",
      "Trainable params: 159,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2800 samples, validate on 700 samples\n",
      "Epoch 1/100\n",
      "2800/2800 [==============================] - 1s 428us/step - loss: 0.7625 - acc: 0.6271 - auc_93: 0.5368 - val_loss: 0.7278 - val_acc: 0.6286 - val_auc_93: 0.5912\n",
      "Epoch 2/100\n",
      "2800/2800 [==============================] - 1s 358us/step - loss: 0.6767 - acc: 0.6250 - auc_93: 0.6106 - val_loss: 0.6717 - val_acc: 0.5943 - val_auc_93: 0.6200\n",
      "Epoch 3/100\n",
      "2800/2800 [==============================] - 1s 348us/step - loss: 0.6152 - acc: 0.6600 - auc_93: 0.6348 - val_loss: 0.6370 - val_acc: 0.6471 - val_auc_93: 0.6551\n",
      "Epoch 4/100\n",
      "2800/2800 [==============================] - 1s 356us/step - loss: 0.5670 - acc: 0.7296 - auc_93: 0.6749 - val_loss: 0.6118 - val_acc: 0.6729 - val_auc_93: 0.6886\n",
      "Epoch 5/100\n",
      "2800/2800 [==============================] - 1s 343us/step - loss: 0.5453 - acc: 0.7311 - auc_93: 0.6991 - val_loss: 0.6169 - val_acc: 0.6829 - val_auc_93: 0.7087\n",
      "Epoch 6/100\n",
      " 128/2800 [>.............................] - ETA: 0s - loss: 0.5149 - acc: 0.7578 - auc_93: 0.7102"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Set hyper-parameters for power mean ensemble \n",
    "N = 5\n",
    "p = 3.5\n",
    "preds = []\n",
    "aucs = []\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               patience=10),\n",
    "                 keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_best_only=True)]\n",
    "\n",
    "for i in tqdm(range(N)):    \n",
    "    X_train, X_test = X_train_conv1d, X_test_conv1d\n",
    "\n",
    "    ##### STEP 1: Randomize Seed\n",
    "    SEED = np.random.randint(1, 10000)              \n",
    "    random.seed(SEED)       \n",
    "    np.random.seed(SEED)     \n",
    "    if tf.__version__[0] < '2':  \n",
    "        tf.set_random_seed(SEED)\n",
    "    else:\n",
    "        tf.random.set_seed(SEED)\n",
    "\n",
    "    ##### STEP 4: Build a CNN Model\n",
    "    \n",
    "    # Define the Model architecture\n",
    "    in_f = Input(shape=(max_len,), dtype='int32', name='forward')\n",
    "    x = layers.Embedding(max_features, emb_dim)(in_f)\n",
    "    x = layers.Conv1D(32, 7, activation='tanh', padding='same')(x)\n",
    "    x = layers.MaxPooling1D(5)(x)\n",
    "    x = layers.Conv1D(32, 7, activation='tanh',padding='same')(x)\n",
    "    #x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(8, activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2')(x)\n",
    "    out = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model1 = Model(in_f, out)\n",
    "    model1.summary()\n",
    "\n",
    "    # Choose the Optimizer and the Cost function\n",
    "    model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',tf.keras.metrics.AUC()]) #RMSprop(lr=1e-4)\n",
    "    train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    # Train the Model\n",
    "    history = model1.fit(train_x, train_y, epochs=100, batch_size=128, \n",
    "                        validation_data=(valid_x,valid_y), callbacks=callbacks, verbose=1)\n",
    "\n",
    "    print(f'CNN learning curve {i+1}/{N}')\n",
    "    plt.plot(history.history[\"loss\"], label=\"train loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Make Prediction\n",
    "    auc = roc_auc_score(valid_y, model1.predict(valid_x).flatten())\n",
    "    aucs.append(auc)\n",
    "    print('AUC', auc)\n",
    "    preds.append(model1.predict(X_test).flatten())   \n",
    "\n",
    "### Validate the Models\n",
    "print('\\nValidation Summary:')\n",
    "aucs = pd.Series(aucs)\n",
    "print(aucs.sort_values(ascending=False))\n",
    "print('mean={:.5f}, std={:.3f}'.format(aucs.mean(), aucs.std()))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "842573936f8fbc2fc01cbbd7ca485be6cb3601bb"
   },
   "source": [
    "### Make Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john9\\Downloads\\3학년 2학기\\머신러닝\\과제\\5차\\Submission\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\john9\\Downloads\\3학년 2학기\\머신러닝\\과제\\5차\\Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "7b6db88f3e4dee0f7f2264916edda431ac7bb72b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ConV1d_p3.5n1_submit_06152225.csv' is ready to submit.\n"
     ]
    }
   ],
   "source": [
    "# Power mean ensemble\n",
    "THRESHOLD = 0.78  # Use only models whose AUC exceeds this value\n",
    "\n",
    "pred = 0\n",
    "n = 0\n",
    "for i in range(N):\n",
    "    if aucs.iloc[i] > THRESHOLD:\n",
    "        pred = pred + preds[i]**p \n",
    "        n += 1\n",
    "pred = pred / n    \n",
    "pred = pred**(1/p)\n",
    "\n",
    "# Make a submission file\n",
    "t = pd.Timestamp.now()\n",
    "fname = f\"ConV1d_p{p}n{n}_submit_{t.month:02}{t.day:02}{t.hour:02}{t.minute:02}.csv\"\n",
    "submissions = pd.concat([pd.Series(IDtest, name=\"cust_id\"), pd.Series(pred, name=\"gender\")] ,axis=1)\n",
    "submissions.to_csv(fname, index=False)\n",
    "print(f\"'{fname}' is ready to submit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db6a418af5947fb6d1546dc8949ac55663504f18"
   },
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
