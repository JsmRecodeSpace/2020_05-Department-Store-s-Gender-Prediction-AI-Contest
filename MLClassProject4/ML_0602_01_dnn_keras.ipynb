{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='tomato'><font color=\"#CC3D3D\"><p>\n",
    "# How to Build Neural Networks using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run import_modules.py  \n",
    "%matplotlib inline\n",
    "\n",
    "# For DNN modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow warning off\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "#  tf.logging.set_verbosity(tf.logging.ERROR) <- logging이 버전업그레이드에서 사용 X라함\n",
    "\n",
    "# from tensorflow import set_random_seed \n",
    "# 위에 코드 안됨에 대한 답변: In Tensoflow2 there is no need to perform\n",
    "# from tensorflow import set_random_seed\n",
    "# in order to run\n",
    "# set_random_seed(x)\n",
    "# (as it was in older version)\n",
    "# Only have to run\n",
    "# import tensorflow\n",
    "# tensorflow.random.set_seed(x)\n",
    "\n",
    "\n",
    "tf.random.set_seed(2020)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import * #Input, Dense\n",
    "from keras.models import * #Model\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.vis_utils import * #model_to_dot\n",
    "\n",
    "from keras import layers\n",
    "from keras import models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle파일 저장 및 읽기\n",
    "# file.to_pickle('test.pickle')\n",
    "# new_df = pd.read_pickle('test.pickle'); new_df\n",
    "\n",
    "# import joblib\n",
    "# joblib.dump((cv, X_train, X_test, y_train, y_test), 'practice1.pkl')\n",
    "\n",
    "# joblib.dump(\n",
    "#     {\n",
    "#         'tfidf' :tfidf,\n",
    "#         'target_names': train.target_names,\n",
    "#         'x_train': x_train,\n",
    "#         'y_train': y_train,\n",
    "#         'x_test': x_test,\n",
    "#         'y_test': y_test,\n",
    "#         },\n",
    "#     'newsgroup.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2450, 62), (1050, 62))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 앞 단계(Feature Enginnering)에서 저장했던 훈련/평가/적용 데이터를 읽어온다.\n",
    "X_train, X_test, y_train, y_test, X_dep, ID_dep = pd.read_pickle('case3_train_test.pkl')\n",
    "\n",
    "# 모델링에 사용되는 최종 학습 및 평가 데이터 확인\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split data into train & validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train/Validation\n",
    "# i = int(round(X_train.shape[0] * 0.75,0))\n",
    "# X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "# X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack layers from input to output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|모듈|사용 예 및 종류|\n",
    "|---|:---:|\n",
    "|Initializer| Dense(16, kernel_initializer='he_normal')|\n",
    "|Regularizer| Dense(16, kernel_regularizer=l2(0.01))|\n",
    "|Activation|relu / elu / selu / softmax / tanh / sigmoid / linear|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매번 모델링을 할 때마다 동일한 결과를 얻으려면 아래 코드를 실행해야 함.\n",
    "SEED = 1              # seed 숫자를 지정\n",
    "random.seed(SEED)     # Python 고정\n",
    "np.random.seed(SEED)  # numpy 고정\n",
    "tf.random.set_seed(SEED) # Tensorflow 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Sequential Model\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 16)                1008      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "2450/2450 [==============================] - 0s 58us/step - loss: 0.7303 - accuracy: 0.4841\n",
      "Epoch 2/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.6759 - accuracy: 0.5800\n",
      "Epoch 3/40\n",
      "2450/2450 [==============================] - 0s 16us/step - loss: 0.6480 - accuracy: 0.6233\n",
      "Epoch 4/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.6316 - accuracy: 0.6437\n",
      "Epoch 5/40\n",
      "2450/2450 [==============================] - 0s 16us/step - loss: 0.6107 - accuracy: 0.6694\n",
      "Epoch 6/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5942 - accuracy: 0.6784\n",
      "Epoch 7/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5844 - accuracy: 0.6829\n",
      "Epoch 8/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5816 - accuracy: 0.6792\n",
      "Epoch 9/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5722 - accuracy: 0.6914\n",
      "Epoch 10/40\n",
      "2450/2450 [==============================] - 0s 16us/step - loss: 0.5592 - accuracy: 0.7102\n",
      "Epoch 11/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5652 - accuracy: 0.7098\n",
      "Epoch 12/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5591 - accuracy: 0.7090\n",
      "Epoch 13/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5528 - accuracy: 0.7176\n",
      "Epoch 14/40\n",
      "2450/2450 [==============================] - 0s 19us/step - loss: 0.5489 - accuracy: 0.7224\n",
      "Epoch 15/40\n",
      "2450/2450 [==============================] - 0s 19us/step - loss: 0.5491 - accuracy: 0.7127\n",
      "Epoch 16/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5443 - accuracy: 0.7273\n",
      "Epoch 17/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5550 - accuracy: 0.7127\n",
      "Epoch 18/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5349 - accuracy: 0.7286\n",
      "Epoch 19/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5315 - accuracy: 0.7204\n",
      "Epoch 20/40\n",
      "2450/2450 [==============================] - 0s 16us/step - loss: 0.5432 - accuracy: 0.7241\n",
      "Epoch 21/40\n",
      "2450/2450 [==============================] - 0s 16us/step - loss: 0.5403 - accuracy: 0.7322\n",
      "Epoch 22/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5306 - accuracy: 0.7371\n",
      "Epoch 23/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5321 - accuracy: 0.7290\n",
      "Epoch 24/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5309 - accuracy: 0.7216\n",
      "Epoch 25/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5299 - accuracy: 0.7351\n",
      "Epoch 26/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5215 - accuracy: 0.7376\n",
      "Epoch 27/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5236 - accuracy: 0.7388\n",
      "Epoch 28/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5187 - accuracy: 0.7424\n",
      "Epoch 29/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5332 - accuracy: 0.7245\n",
      "Epoch 30/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5223 - accuracy: 0.7355\n",
      "Epoch 31/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5198 - accuracy: 0.7318\n",
      "Epoch 32/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5116 - accuracy: 0.7457\n",
      "Epoch 33/40\n",
      "2450/2450 [==============================] - 0s 15us/step - loss: 0.5115 - accuracy: 0.7404\n",
      "Epoch 34/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5218 - accuracy: 0.7380\n",
      "Epoch 35/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5142 - accuracy: 0.7392\n",
      "Epoch 36/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5157 - accuracy: 0.7437\n",
      "Epoch 37/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5124 - accuracy: 0.7351\n",
      "Epoch 38/40\n",
      "2450/2450 [==============================] - 0s 18us/step - loss: 0.5121 - accuracy: 0.7290\n",
      "Epoch 39/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5165 - accuracy: 0.7424\n",
      "Epoch 40/40\n",
      "2450/2450 [==============================] - 0s 17us/step - loss: 0.5100 - accuracy: 0.7441\n",
      "train, loss and metric: [0.4787112638901691, 0.7579591870307922]\n",
      "test, loss and metric: [0.5728030210449582, 0.7085714340209961]\n",
      "0.753547508230219\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(\"#### Sequential Model\")\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# validation_data=(X_valid, y_valid)\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),]\n",
    "hist = model.fit(X_train, y_train, batch_size=64, epochs=40, callbacks=callbacks, \n",
    "                 shuffle=False, verbose=1)\n",
    "\n",
    "loss_and_metric = model.evaluate(X_train, y_train, batch_size=128, verbose=0)\n",
    "print(\"train, loss and metric: {}\".format(loss_and_metric))\n",
    "loss_and_metric = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "print(\"test, loss and metric: {}\".format(loss_and_metric))\n",
    "print(roc_auc_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input => Dense + Dense + ... => output\n",
    "# Model(input, output)\n",
    " ## 입력층을 먼저 얘기하고, 입력 다음을 케라스에서는 dense라 하는데\n",
    "    # 이거를 쌓아서 최종 output까지 쌓아줌\n",
    "# functional x가 무엇이냐\n",
    "input = Input(shape=(X_train.shape[1],)) # 입력층: X_train의 열의 갯수, 피쳐의 갯수\n",
    "x = Dense(16, activation='relu')(input) # 다음층부터 하나의 층을 하나의 dense라 함\n",
    "                                        # 첫번째 은닉층의 뉴런이 16개이다.\n",
    "                                        # Dense 인자에 kernel_initializer, kernel_regularizer, bias_regularizer 등 잇음\n",
    "x = Dropout(0.3)(x) # \n",
    "x = Dense(8, activation='relu')(x) # 이러한 층의 뉴런의 수를 우리가 지정한다. -\n",
    "                                    # 함수를 relu를 지정햇는데 sigmoid랑 다른 다른 함수이다.\n",
    "x = Dropout(0.2)(x)    \n",
    "\n",
    "output = Dense(1, activation='sigmoid')(x) # 출력층, 하나만 잇으면 되서 뉴런이 1개임(62 -> 16 -> 8 -> 1)\n",
    "model = Model(input, output) # 모델 셋팅한 것 \n",
    "\n",
    "# 여기가 굉장히 중요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summarize & visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                1008      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1914\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ed9016e671af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 뉴럴 넷의 상태를 보여줌\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 웨이트가 1153번이 학습되는 것\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dashed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         raise OSError(\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "model.summary() # 뉴럴 넷의 상태를 보여줌\n",
    "Image(model_to_dot(model,show_shapes=True, show_layer_names=False).create(prog='dot', format='png'))\n",
    "# 웨이트가 1153번이 학습되는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the optimizer and the cost function\n",
    "<img align='left' src='http://drive.google.com/uc?export=view&id=1xybqHMvcDDfUYSN3FLQ6Y1708QkiZSJt' style=\"width: 70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Optimizer의 예:*\n",
    "- SGD(lr=0.01, momentum=0.9)\n",
    "- RMSprop(lr=0.001, rho=0.9)\n",
    "- Adagrad(lr=0.01)\n",
    "- Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary 일때는 시그모이드 \n",
    "# multi 일때는 softmax를 씀\n",
    "# 회귀문제일때는 출력노드의 엑티베이션이 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바로 fit 들어가지 않고 케라스는 compile단계가 하나 더 있다.\n",
    "# 밑에와 같은 것들 설정하는 것\n",
    "\n",
    "# 옵티마이저: sgd는 경사하강법을 통해서 최적의 파라미터 찾는것, metrics에 \n",
    "                                #auc 넣으면 속도가 느려서 accuaacy쓰곤 함\n",
    "    \n",
    "    # 옵티마이저를 sgd말고 아담같은 다른 더 좋은 옵티마이저를 쓸거냐 말거냐도 중요하다\n",
    "# loss, optimizer, metrics 설정 \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set learning conditions & fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch size, epoch, 조기종료조건 등 설정\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=20),]\n",
    "            # keras.callbacks.ModelCheckpoint(filepath='best_nn_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=64, epochs=40, callbacks=callbacks, \n",
    "                 shuffle=False, verbose=1)\n",
    "\n",
    "# 데이터 2000개인가 3000개이를 64개 batch_size로 쪼개서 64개 한꺼번에 계산 및 학습해서 weight값 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize training history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할때는 계속 내려가고\n",
    "# validation loss가 내려가다가 올라가는 그런 모양에서 과적합인지 알수잇는것\n",
    "\n",
    "plt.plot(hist.history[\"loss\"], label=\"train loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# 뉴럴넷이 고려할게 너무 많아서(하이퍼 파라미터 뿐만 아니라 아키택쳐)까지\n",
    "# 해야해서 머신러닝보다 더 좋은 모델링을 하기 힘들다\n",
    "# 맛보기로 일단 해보는 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "# 사이킷런에서는 score라 하는것을 케라스에서는 evaluteat 이라 함\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC\n",
    "roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "\n",
    "# 사이킷런은 precit랑 predict_proba가 잇는데 \n",
    "# 케라스에서는 predict가 predict_proba에 해당하고 사이킷런의 predict을 하려면 따로 설정해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates output predictions for the input samples\n",
    "model.predict(X_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_dep).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class labels\n",
    "np.where(model.predict(X_dep) > 0.5, 1, 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make submissions\n",
    "pd.DataFrame({'cust_id': ID_dep, 'gender': model.predict(X_dep).flatten()}).to_csv('dnn_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 7: Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 형식으로 저장\n",
    "# with open('nn_model.pkl', 'wb') as f:\n",
    "#    pickle.dump(model, f)\n",
    "\n",
    "# 추후 저장한 모형 불러올 때: \n",
    "# model = pd.read_pickle('nn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5 형식으로 저장\n",
    "# model.save('nn_model.h5')\n",
    "\n",
    "# 추후 저장한 모형 불러올 때: \n",
    "# model = load_model('nn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#CC3D3D\"><p>\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
