{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run import_modules.py  \n",
    "%matplotlib inline\n",
    "\n",
    "# For DNN modeling\n",
    "import tensorflow as tf\n",
    "\n",
    "# Tensorflow warning off\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.random.set_seed(2020)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import * #Input, Dense\n",
    "from keras.models import * #Model\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.vis_utils import * #model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>62</th>\n",
       "      <th>6</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>29</th>\n",
       "      <th>17</th>\n",
       "      <th>15</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>20</th>\n",
       "      <th>54</th>\n",
       "      <th>31</th>\n",
       "      <th>42</th>\n",
       "      <th>8</th>\n",
       "      <th>43</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>0.548899</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.571544</td>\n",
       "      <td>0.359882</td>\n",
       "      <td>-1.015259</td>\n",
       "      <td>0.173466</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>0.145489</td>\n",
       "      <td>-0.245481</td>\n",
       "      <td>-0.146008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>0.463131</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>0.118152</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>-0.462602</td>\n",
       "      <td>-0.233664</td>\n",
       "      <td>0.028230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.320871</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.349123</td>\n",
       "      <td>-0.971234</td>\n",
       "      <td>-0.717802</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>0.081508</td>\n",
       "      <td>-0.222676</td>\n",
       "      <td>-0.225992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022743</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>-0.060406</td>\n",
       "      <td>-0.022906</td>\n",
       "      <td>-0.630031</td>\n",
       "      <td>-0.069524</td>\n",
       "      <td>-0.145507</td>\n",
       "      <td>-0.335948</td>\n",
       "      <td>-0.199120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.106787</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>0.836666</td>\n",
       "      <td>0.173059</td>\n",
       "      <td>1.202737</td>\n",
       "      <td>0.258409</td>\n",
       "      <td>-0.074363</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.461857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098704</td>\n",
       "      <td>-0.390307</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>-0.247680</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>0.333168</td>\n",
       "      <td>-0.140870</td>\n",
       "      <td>0.056745</td>\n",
       "      <td>0.719127</td>\n",
       "      <td>0.448463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>0.042551</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.423766</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-1.347939</td>\n",
       "      <td>0.636159</td>\n",
       "      <td>-0.172775</td>\n",
       "      <td>-0.243410</td>\n",
       "      <td>-0.199761</td>\n",
       "      <td>0.531453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037228</td>\n",
       "      <td>-0.229491</td>\n",
       "      <td>0.176807</td>\n",
       "      <td>0.112770</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>0.252694</td>\n",
       "      <td>-0.168742</td>\n",
       "      <td>-0.597824</td>\n",
       "      <td>0.560783</td>\n",
       "      <td>-0.126377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.154722</td>\n",
       "      <td>0.787083</td>\n",
       "      <td>-0.567632</td>\n",
       "      <td>0.867433</td>\n",
       "      <td>0.464774</td>\n",
       "      <td>0.066818</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>0.337979</td>\n",
       "      <td>0.406158</td>\n",
       "      <td>-0.659014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226443</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.095207</td>\n",
       "      <td>0.045055</td>\n",
       "      <td>-0.016248</td>\n",
       "      <td>-0.867206</td>\n",
       "      <td>-0.181159</td>\n",
       "      <td>-0.327944</td>\n",
       "      <td>-0.049611</td>\n",
       "      <td>-0.236074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.147064</td>\n",
       "      <td>0.787083</td>\n",
       "      <td>-0.160119</td>\n",
       "      <td>-1.468848</td>\n",
       "      <td>0.211420</td>\n",
       "      <td>-0.198602</td>\n",
       "      <td>0.118466</td>\n",
       "      <td>-0.129578</td>\n",
       "      <td>-0.058548</td>\n",
       "      <td>-0.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>0.327446</td>\n",
       "      <td>0.048855</td>\n",
       "      <td>-0.014029</td>\n",
       "      <td>0.004971</td>\n",
       "      <td>-0.773520</td>\n",
       "      <td>0.071237</td>\n",
       "      <td>-0.030003</td>\n",
       "      <td>0.458061</td>\n",
       "      <td>0.717578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>0.879341</td>\n",
       "      <td>0.787083</td>\n",
       "      <td>-0.245290</td>\n",
       "      <td>-1.022907</td>\n",
       "      <td>-0.232751</td>\n",
       "      <td>0.093136</td>\n",
       "      <td>0.178418</td>\n",
       "      <td>-0.038884</td>\n",
       "      <td>-0.036894</td>\n",
       "      <td>0.090965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167855</td>\n",
       "      <td>-0.163514</td>\n",
       "      <td>-0.030396</td>\n",
       "      <td>-0.278591</td>\n",
       "      <td>0.454730</td>\n",
       "      <td>-0.511544</td>\n",
       "      <td>0.062086</td>\n",
       "      <td>0.112773</td>\n",
       "      <td>0.229144</td>\n",
       "      <td>0.219065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>-0.195824</td>\n",
       "      <td>-0.579319</td>\n",
       "      <td>0.249590</td>\n",
       "      <td>0.050197</td>\n",
       "      <td>-1.242144</td>\n",
       "      <td>0.046300</td>\n",
       "      <td>-0.024794</td>\n",
       "      <td>0.169448</td>\n",
       "      <td>-0.137269</td>\n",
       "      <td>-0.072191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138992</td>\n",
       "      <td>-0.172225</td>\n",
       "      <td>0.106762</td>\n",
       "      <td>-0.225918</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.100568</td>\n",
       "      <td>0.022075</td>\n",
       "      <td>-0.042563</td>\n",
       "      <td>0.410268</td>\n",
       "      <td>0.431392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>0.375166</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>-0.286549</td>\n",
       "      <td>0.105563</td>\n",
       "      <td>-1.155629</td>\n",
       "      <td>0.382463</td>\n",
       "      <td>0.244659</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>-0.107648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090222</td>\n",
       "      <td>-0.271835</td>\n",
       "      <td>-0.110292</td>\n",
       "      <td>0.077271</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>0.306769</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>-0.201401</td>\n",
       "      <td>-0.006521</td>\n",
       "      <td>-0.088862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>-0.190611</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>0.258078</td>\n",
       "      <td>0.919124</td>\n",
       "      <td>0.061924</td>\n",
       "      <td>0.708540</td>\n",
       "      <td>-0.680904</td>\n",
       "      <td>0.266762</td>\n",
       "      <td>0.289444</td>\n",
       "      <td>0.288614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154277</td>\n",
       "      <td>0.431517</td>\n",
       "      <td>0.055057</td>\n",
       "      <td>-0.098088</td>\n",
       "      <td>-0.107360</td>\n",
       "      <td>0.179838</td>\n",
       "      <td>-0.261895</td>\n",
       "      <td>0.428249</td>\n",
       "      <td>0.750066</td>\n",
       "      <td>-0.210436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2450 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         62        6         4         1         2         29  \\\n",
       "849   0.548899 -0.211737  0.571544  0.359882 -1.015259  0.173466  0.183404   \n",
       "820   0.320871 -0.211737  0.056200  0.349123 -0.971234 -0.717802 -0.146723   \n",
       "886   0.106787 -0.008796  0.836666  0.173059  1.202737  0.258409 -0.074363   \n",
       "1288  0.042551 -0.211737  0.423766 -0.014149 -1.347939  0.636159 -0.172775   \n",
       "414   0.154722  0.787083 -0.567632  0.867433  0.464774  0.066818 -0.017657   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "835   0.147064  0.787083 -0.160119 -1.468848  0.211420 -0.198602  0.118466   \n",
       "3264  0.879341  0.787083 -0.245290 -1.022907 -0.232751  0.093136  0.178418   \n",
       "1653 -0.195824 -0.579319  0.249590  0.050197 -1.242144  0.046300 -0.024794   \n",
       "2607  0.375166 -0.211737 -0.286549  0.105563 -1.155629  0.382463  0.244659   \n",
       "2732 -0.190611 -0.008796  0.258078  0.919124  0.061924  0.708540 -0.680904   \n",
       "\n",
       "            17        15        13  ...        34        20        54  \\\n",
       "849   0.145489 -0.245481 -0.146008  ... -0.001879  0.463131  0.042479   \n",
       "820   0.081508 -0.222676 -0.225992  ... -0.022743  0.108870  0.028156   \n",
       "886   0.048298  0.149960  0.461857  ...  0.098704 -0.390307  0.050151   \n",
       "1288 -0.243410 -0.199761  0.531453  ...  0.037228 -0.229491  0.176807   \n",
       "414   0.337979  0.406158 -0.659014  ... -0.226443 -0.028724 -0.095207   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "835  -0.129578 -0.058548 -0.260203  ... -0.214193  0.327446  0.048855   \n",
       "3264 -0.038884 -0.036894  0.090965  ...  0.167855 -0.163514 -0.030396   \n",
       "1653  0.169448 -0.137269 -0.072191  ...  0.138992 -0.172225  0.106762   \n",
       "2607  0.015792  0.059937 -0.107648  ...  0.090222 -0.271835 -0.110292   \n",
       "2732  0.266762  0.289444  0.288614  ...  0.154277  0.431517  0.055057   \n",
       "\n",
       "            31        42        8         43        12        10        18  \n",
       "849   0.118152 -0.014069  0.033457 -0.048870 -0.462602 -0.233664  0.028230  \n",
       "820  -0.060406 -0.022906 -0.630031 -0.069524 -0.145507 -0.335948 -0.199120  \n",
       "886  -0.247680  0.161154  0.333168 -0.140870  0.056745  0.719127  0.448463  \n",
       "1288  0.112770  0.052658  0.252694 -0.168742 -0.597824  0.560783 -0.126377  \n",
       "414   0.045055 -0.016248 -0.867206 -0.181159 -0.327944 -0.049611 -0.236074  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "835  -0.014029  0.004971 -0.773520  0.071237 -0.030003  0.458061  0.717578  \n",
       "3264 -0.278591  0.454730 -0.511544  0.062086  0.112773  0.229144  0.219065  \n",
       "1653 -0.225918  0.047244  0.100568  0.022075 -0.042563  0.410268  0.431392  \n",
       "2607  0.077271  0.027430  0.306769  0.023316 -0.201401 -0.006521 -0.088862  \n",
       "2732 -0.098088 -0.107360  0.179838 -0.261895  0.428249  0.750066 -0.210436  \n",
       "\n",
       "[2450 rows x 62 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, X_dep, ID_dep = pd.read_pickle('case3_train_test.pkl')\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_dep, ID_dep = pd.read_pickle('case3_train_test.pkl')\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>62</th>\n",
       "      <th>6</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>29</th>\n",
       "      <th>17</th>\n",
       "      <th>15</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>20</th>\n",
       "      <th>54</th>\n",
       "      <th>31</th>\n",
       "      <th>42</th>\n",
       "      <th>8</th>\n",
       "      <th>43</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>0.548899</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.571544</td>\n",
       "      <td>0.359882</td>\n",
       "      <td>-1.015259</td>\n",
       "      <td>0.173466</td>\n",
       "      <td>0.183404</td>\n",
       "      <td>0.145489</td>\n",
       "      <td>-0.245481</td>\n",
       "      <td>-0.146008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>0.463131</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>0.118152</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>-0.462602</td>\n",
       "      <td>-0.233664</td>\n",
       "      <td>0.028230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.320871</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.349123</td>\n",
       "      <td>-0.971234</td>\n",
       "      <td>-0.717802</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>0.081508</td>\n",
       "      <td>-0.222676</td>\n",
       "      <td>-0.225992</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022743</td>\n",
       "      <td>0.108870</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>-0.060406</td>\n",
       "      <td>-0.022906</td>\n",
       "      <td>-0.630031</td>\n",
       "      <td>-0.069524</td>\n",
       "      <td>-0.145507</td>\n",
       "      <td>-0.335948</td>\n",
       "      <td>-0.199120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.106787</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>0.836666</td>\n",
       "      <td>0.173059</td>\n",
       "      <td>1.202737</td>\n",
       "      <td>0.258409</td>\n",
       "      <td>-0.074363</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>0.149960</td>\n",
       "      <td>0.461857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098704</td>\n",
       "      <td>-0.390307</td>\n",
       "      <td>0.050151</td>\n",
       "      <td>-0.247680</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>0.333168</td>\n",
       "      <td>-0.140870</td>\n",
       "      <td>0.056745</td>\n",
       "      <td>0.719127</td>\n",
       "      <td>0.448463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>0.042551</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.423766</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>-1.347939</td>\n",
       "      <td>0.636159</td>\n",
       "      <td>-0.172775</td>\n",
       "      <td>-0.243410</td>\n",
       "      <td>-0.199761</td>\n",
       "      <td>0.531453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037228</td>\n",
       "      <td>-0.229491</td>\n",
       "      <td>0.176807</td>\n",
       "      <td>0.112770</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>0.252694</td>\n",
       "      <td>-0.168742</td>\n",
       "      <td>-0.597824</td>\n",
       "      <td>0.560783</td>\n",
       "      <td>-0.126377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.154722</td>\n",
       "      <td>0.787083</td>\n",
       "      <td>-0.567632</td>\n",
       "      <td>0.867433</td>\n",
       "      <td>0.464774</td>\n",
       "      <td>0.066818</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>0.337979</td>\n",
       "      <td>0.406158</td>\n",
       "      <td>-0.659014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226443</td>\n",
       "      <td>-0.028724</td>\n",
       "      <td>-0.095207</td>\n",
       "      <td>0.045055</td>\n",
       "      <td>-0.016248</td>\n",
       "      <td>-0.867206</td>\n",
       "      <td>-0.181159</td>\n",
       "      <td>-0.327944</td>\n",
       "      <td>-0.049611</td>\n",
       "      <td>-0.236074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>-0.928741</td>\n",
       "      <td>-0.008151</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>-0.431760</td>\n",
       "      <td>1.916867</td>\n",
       "      <td>0.652490</td>\n",
       "      <td>0.229067</td>\n",
       "      <td>0.269690</td>\n",
       "      <td>-0.114792</td>\n",
       "      <td>0.256507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522800</td>\n",
       "      <td>0.344829</td>\n",
       "      <td>-0.108672</td>\n",
       "      <td>-0.867108</td>\n",
       "      <td>-0.019721</td>\n",
       "      <td>0.069372</td>\n",
       "      <td>0.848311</td>\n",
       "      <td>-1.090585</td>\n",
       "      <td>-0.142489</td>\n",
       "      <td>-0.350349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.502392</td>\n",
       "      <td>-0.579319</td>\n",
       "      <td>-0.471605</td>\n",
       "      <td>1.034412</td>\n",
       "      <td>-0.384312</td>\n",
       "      <td>0.414507</td>\n",
       "      <td>-0.114771</td>\n",
       "      <td>-0.019339</td>\n",
       "      <td>-0.156532</td>\n",
       "      <td>-0.177005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088521</td>\n",
       "      <td>-0.335577</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.083238</td>\n",
       "      <td>-0.034318</td>\n",
       "      <td>-0.616039</td>\n",
       "      <td>-0.175315</td>\n",
       "      <td>-0.376759</td>\n",
       "      <td>-0.349107</td>\n",
       "      <td>0.280511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>-1.185443</td>\n",
       "      <td>-0.008796</td>\n",
       "      <td>0.076312</td>\n",
       "      <td>0.237582</td>\n",
       "      <td>2.202188</td>\n",
       "      <td>-1.249115</td>\n",
       "      <td>-0.192562</td>\n",
       "      <td>1.473840</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>-0.326854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020377</td>\n",
       "      <td>-0.615013</td>\n",
       "      <td>0.076285</td>\n",
       "      <td>0.149394</td>\n",
       "      <td>0.144305</td>\n",
       "      <td>0.045316</td>\n",
       "      <td>-0.141914</td>\n",
       "      <td>-0.081162</td>\n",
       "      <td>0.613865</td>\n",
       "      <td>-0.108081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0.007327</td>\n",
       "      <td>-0.008151</td>\n",
       "      <td>0.415069</td>\n",
       "      <td>0.829052</td>\n",
       "      <td>2.302148</td>\n",
       "      <td>-1.605445</td>\n",
       "      <td>-0.645921</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>0.364496</td>\n",
       "      <td>-0.565396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099455</td>\n",
       "      <td>0.258509</td>\n",
       "      <td>-0.085870</td>\n",
       "      <td>-0.450350</td>\n",
       "      <td>-0.961301</td>\n",
       "      <td>-0.341927</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>-0.433843</td>\n",
       "      <td>-0.456474</td>\n",
       "      <td>0.471285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.397536</td>\n",
       "      <td>-0.211737</td>\n",
       "      <td>0.319032</td>\n",
       "      <td>0.463958</td>\n",
       "      <td>-1.310845</td>\n",
       "      <td>1.128711</td>\n",
       "      <td>-0.047155</td>\n",
       "      <td>-0.023963</td>\n",
       "      <td>-0.068132</td>\n",
       "      <td>-0.472606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099933</td>\n",
       "      <td>-0.086795</td>\n",
       "      <td>-0.189629</td>\n",
       "      <td>0.071361</td>\n",
       "      <td>-0.031526</td>\n",
       "      <td>-0.075372</td>\n",
       "      <td>-0.047107</td>\n",
       "      <td>-0.077676</td>\n",
       "      <td>-0.591946</td>\n",
       "      <td>-0.392171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1960 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         62        6         4         1         2         29  \\\n",
       "849   0.548899 -0.211737  0.571544  0.359882 -1.015259  0.173466  0.183404   \n",
       "820   0.320871 -0.211737  0.056200  0.349123 -0.971234 -0.717802 -0.146723   \n",
       "886   0.106787 -0.008796  0.836666  0.173059  1.202737  0.258409 -0.074363   \n",
       "1288  0.042551 -0.211737  0.423766 -0.014149 -1.347939  0.636159 -0.172775   \n",
       "414   0.154722  0.787083 -0.567632  0.867433  0.464774  0.066818 -0.017657   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2671 -0.928741 -0.008151  0.016220 -0.431760  1.916867  0.652490  0.229067   \n",
       "603   0.502392 -0.579319 -0.471605  1.034412 -0.384312  0.414507 -0.114771   \n",
       "1289 -1.185443 -0.008796  0.076312  0.237582  2.202188 -1.249115 -0.192562   \n",
       "2502  0.007327 -0.008151  0.415069  0.829052  2.302148 -1.605445 -0.645921   \n",
       "63    0.397536 -0.211737  0.319032  0.463958 -1.310845  1.128711 -0.047155   \n",
       "\n",
       "            17        15        13  ...        34        20        54  \\\n",
       "849   0.145489 -0.245481 -0.146008  ... -0.001879  0.463131  0.042479   \n",
       "820   0.081508 -0.222676 -0.225992  ... -0.022743  0.108870  0.028156   \n",
       "886   0.048298  0.149960  0.461857  ...  0.098704 -0.390307  0.050151   \n",
       "1288 -0.243410 -0.199761  0.531453  ...  0.037228 -0.229491  0.176807   \n",
       "414   0.337979  0.406158 -0.659014  ... -0.226443 -0.028724 -0.095207   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2671  0.269690 -0.114792  0.256507  ...  0.522800  0.344829 -0.108672   \n",
       "603  -0.019339 -0.156532 -0.177005  ... -0.088521 -0.335577  0.014870   \n",
       "1289  1.473840  0.392467 -0.326854  ... -0.020377 -0.615013  0.076285   \n",
       "2502  0.013671  0.364496 -0.565396  ...  0.099455  0.258509 -0.085870   \n",
       "63   -0.023963 -0.068132 -0.472606  ...  0.099933 -0.086795 -0.189629   \n",
       "\n",
       "            31        42        8         43        12        10        18  \n",
       "849   0.118152 -0.014069  0.033457 -0.048870 -0.462602 -0.233664  0.028230  \n",
       "820  -0.060406 -0.022906 -0.630031 -0.069524 -0.145507 -0.335948 -0.199120  \n",
       "886  -0.247680  0.161154  0.333168 -0.140870  0.056745  0.719127  0.448463  \n",
       "1288  0.112770  0.052658  0.252694 -0.168742 -0.597824  0.560783 -0.126377  \n",
       "414   0.045055 -0.016248 -0.867206 -0.181159 -0.327944 -0.049611 -0.236074  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2671 -0.867108 -0.019721  0.069372  0.848311 -1.090585 -0.142489 -0.350349  \n",
       "603   0.083238 -0.034318 -0.616039 -0.175315 -0.376759 -0.349107  0.280511  \n",
       "1289  0.149394  0.144305  0.045316 -0.141914 -0.081162  0.613865 -0.108081  \n",
       "2502 -0.450350 -0.961301 -0.341927  0.119224 -0.433843 -0.456474  0.471285  \n",
       "63    0.071361 -0.031526 -0.075372 -0.047107 -0.077676 -0.591946 -0.392171  \n",
       "\n",
       "[1960 rows x 62 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1층: 4,드롭1: 0,2층: 4, 드롭2: 0, 3층: 4\n",
      "0.754451755845315\n",
      "1층: 4,드롭1: 0,2층: 4, 드롭2: 0, 3층: 16\n",
      "0.7520051984451639\n",
      "1층: 4,드롭1: 0,2층: 8, 드롭2: 0.2, 3층: 8\n",
      "0.7528840018632981\n",
      "1층: 4,드롭1: 0,2층: 8, 드롭2: 0.3, 3층: 4\n",
      "0.7529681634378633\n",
      "1층: 4,드롭1: 0,2층: 8, 드롭2: 0.4, 3층: 8\n",
      "0.7552542266725645\n",
      "1층: 4,드롭1: 0,2층: 16, 드롭2: 0, 3층: 4\n",
      "0.7533791850810887\n",
      "1층: 4,드롭1: 0,2층: 16, 드롭2: 0.2, 3층: 8\n",
      "0.7549488963090256\n",
      "1층: 4,드롭1: 0,2층: 16, 드롭2: 0.3, 3층: 16\n",
      "0.751797730377631\n",
      "1층: 4,드롭1: 0,2층: 16, 드롭2: 0.4, 3층: 8\n",
      "0.7521226332003712\n",
      "1층: 4,드롭1: 0,2층: 32, 드롭2: 0, 3층: 4\n",
      "0.7580433021087367\n",
      "1층: 4,드롭1: 0,2층: 32, 드롭2: 0, 3층: 32\n",
      "0.7507114588919639\n",
      "1층: 4,드롭1: 0,2층: 32, 드롭2: 0.2, 3층: 4\n",
      "0.7601042820626239\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0, 3층: 4\n",
      "0.7557631106117959\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0, 3층: 8\n",
      "0.7504276582335464\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0, 3층: 16\n",
      "0.7534555176719734\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0, 3층: 32\n",
      "0.7549919557192684\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.3, 3층: 8\n",
      "0.7572075581008451\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.3, 3층: 16\n",
      "0.7511988131260741\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.4, 3층: 4\n",
      "0.7516235354907402\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.4, 3층: 32\n",
      "0.7516098347692994\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.5, 3층: 4\n",
      "0.7592039489393685\n",
      "1층: 4,드롭1: 0.2,2층: 4, 드롭2: 0.5, 3층: 32\n",
      "0.7507682190236474\n",
      "1층: 4,드롭1: 0.2,2층: 8, 드롭2: 0, 3층: 8\n",
      "0.7526276026477623\n",
      "1층: 4,드롭1: 0.2,2층: 8, 드롭2: 0.2, 3층: 4\n",
      "0.7549802122437476\n",
      "1층: 4,드롭1: 0.2,2층: 8, 드롭2: 0.2, 3층: 16\n",
      "0.7516137492611397\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2382\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2384\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Operation 'dropout_504/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m       \u001b[0mxla_compile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaCompile\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2386\u001b[0m       \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2387\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2388\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation 'dropout_504/cond' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-c5aa306f5487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                     hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n\u001b[1;32m---> 37\u001b[1;33m                         batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# visualize training history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbolic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   3023\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3024\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3025\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients_v2\u001b[1;34m(ys, xs, grad_ys, name, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    272\u001b[0m         \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgate_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m         unconnected_gradients)\n\u001b[0m\u001b[0;32m    275\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 679\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    680\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_XlaScope\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    677\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 679\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    680\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;31m# Get the if operator (this logic handles the case where op is a MockOp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m   \u001b[0mif_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m   \u001b[0mtrue_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfalse_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_func_graphs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mif_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m   \u001b[1;31m# Note: op.graph != ops.get_default_graph() when we are computing the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m   \u001b[1;31m# of a nested cond.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36mget_func_graphs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    330\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"If\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StatelessIf\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     return (_get_func_graph_for_branch(op.get_attr(\"then_branch\")),\n\u001b[1;32m--> 332\u001b[1;33m             _get_func_graph_for_branch(op.get_attr(\"else_branch\")))\n\u001b[0m\u001b[0;32m    333\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Case\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     return [_get_func_graph_for_branch(branch_fn)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graph_for_branch\u001b[1;34m(name_attr_list)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m       func_graph = function_def_to_graph.function_def_to_graph(\n\u001b[1;32m--> 322\u001b[1;33m           fdef, input_shapes)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mexternal_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_t\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m       \u001b[0mcustom_gradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexternal_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, input_shapes, copy_functions)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;31m# Add all function nodes to the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mimporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_graph_def_for_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name)\u001b[0m\n\u001b[0;32m    410\u001b[0m   \u001b[1;34m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m   return _import_graph_def_internal(\n\u001b[1;32m--> 412\u001b[1;33m       graph_def, validate_colocation_constraints=False, name=name)\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)\u001b[0m\n\u001b[0;32m    496\u001b[0m   \u001b[1;31m# _ProcessNewOps.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;33m<\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dr1st = dense_range_1st_layer = [4, 8, 16, 32]\n",
    "dr2nd = dense_range_2nd_layer = [4, 8, 16, 32]\n",
    "dr3rd = dense_range_3rd_layer = [4, 8, 16, 32]\n",
    "drop1st = dropout_range_1st_layer = [0, 0.2, 0.3, 0.4, 0.5]\n",
    "drop2nd = dropout_range_2nd_layer = [0, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for dr1 in dr1st:\n",
    "    \n",
    "    for drop1 in drop1st:\n",
    "    \n",
    "        for dr2 in dr2nd:\n",
    "        \n",
    "            for drop2 in drop2nd:\n",
    "                \n",
    "                for dr3 in dr3rd:\n",
    "\n",
    "        \n",
    "# model architecture\n",
    "                    model = Sequential(name = 'dnn model')\n",
    "                    model.add(Dense(dr1, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "                    model.add(Dropout(drop1))\n",
    "                    model.add(Dense(dr2, activation='relu'))\n",
    "                    model.add(Dropout(drop2))\n",
    "                    model.add(Dense(dr3, activation='relu'))\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "                    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "                    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "                    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "                        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#                    print(model.evaluate(X_test, y_test))\n",
    "                    if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "                        print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "                        print(roc_auc_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2482,)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_dep).flatten()\n",
    "print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3500</td>\n",
       "      <td>0.778295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3501</td>\n",
       "      <td>0.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3502</td>\n",
       "      <td>0.139749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3503</td>\n",
       "      <td>0.169812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3504</td>\n",
       "      <td>0.267438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>5977</td>\n",
       "      <td>0.516476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>5978</td>\n",
       "      <td>0.382308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.816023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>5980</td>\n",
       "      <td>0.276791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>5981</td>\n",
       "      <td>0.376510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id    gender\n",
       "0        3500  0.778295\n",
       "1        3501  0.210400\n",
       "2        3502  0.139749\n",
       "3        3503  0.169812\n",
       "4        3504  0.267438\n",
       "...       ...       ...\n",
       "2477     5977  0.516476\n",
       "2478     5978  0.382308\n",
       "2479     5979  0.816023\n",
       "2480     5980  0.276791\n",
       "2481     5981  0.376510\n",
       "\n",
       "[2482 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make submissions\n",
    "\n",
    "pd.DataFrame({'cust_id': ID_dep, 'gender': pred}).to_csv('submission_dnn_nm.csv', index=False, encoding='cp949')\n",
    "pd.read_csv('submission_dnn_nm.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 형식으로 저장\n",
    "with open('nm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 저장한 모형 불러올 때\n",
    "model = pd.read_pickle('nm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5 형식으로 저장\n",
    "model.save('nm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추후 저장한 모형 불러올 때\n",
    "model = load_model('nm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. libraries, read data     \n",
    "2. data engineering   \n",
    "3. model architecture, choose the optimizer and the cost function, train the model   \n",
    "4. visualize training history, evaluate the model performance   \n",
    "5. predict unseen data, save the model for future use   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
