{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from vecstack import stacking\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "# Tensorflow warning off\n",
    "if tf.__version__[0] < '2':\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import * #Input, Dense\n",
    "from keras.models import * #Model\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras.regularizers import *\n",
    "from keras.constraints import *\n",
    "from keras.utils.np_utils import *\n",
    "from keras.utils.vis_utils import * #model_to_dot\n",
    "from keras.preprocessing.image import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import *\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras import Input\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.constraints import max_norm\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모형 학습 시 RMSE를 계산하는 함수\n",
    "def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "# 예측값을 저장할 폴더 생성\n",
    "folder = 'Ensemble'\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Ensemble Models \n",
    "# 생성된 다수의 DNN 모형을 power mean하여 앙상블\n",
    "\n",
    "# nf = 0\n",
    "# for f in os.listdir(folder):\n",
    "#     ext = os.path.splitext(f)[-1]\n",
    "#     if ext == '.csv': \n",
    "#         s = pd.read_csv(folder+\"/\"+f)\n",
    "#     else: \n",
    "#         continue\n",
    "#     if len(s.columns) !=2:\n",
    "#         continue\n",
    "#     if nf == 0: \n",
    "#         slist = s\n",
    "#     else: \n",
    "#         slist = pd.merge(slist, s, on=\"item_id\")\n",
    "#     nf += 1\n",
    "\n",
    "# p = 4.5 # 이 값에 따라 성능이 달라짐 (p=1: 산술평균, p>1: 멱평균)    \n",
    "# if nf >= 2:\n",
    "#     pred = 0\n",
    "#     for j in range(nf): pred = pred + slist.iloc[:,j+1]**p \n",
    "#     pred = pred / nf    \n",
    "#     pred = pred**(1/p)\n",
    "\n",
    "#     submission = pd.DataFrame({'item_id': slist.item_id, 'item_cnt_month': pred})\n",
    "#     t = pd.Timestamp.now()\n",
    "#     fname = f\"p{p}mean_dnn_submission_{t.month:02}{t.day:02}_{t.hour:02}{t.minute:02}.csv\"\n",
    "#     submission.to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 중분류 구매건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625380</td>\n",
       "      <td>0.034396</td>\n",
       "      <td>-0.672246</td>\n",
       "      <td>0.441779</td>\n",
       "      <td>0.159294</td>\n",
       "      <td>-0.598718</td>\n",
       "      <td>0.325886</td>\n",
       "      <td>-0.936302</td>\n",
       "      <td>0.305429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143142</td>\n",
       "      <td>0.118564</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.089901</td>\n",
       "      <td>-0.111054</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>0.140365</td>\n",
       "      <td>0.117912</td>\n",
       "      <td>-0.126485</td>\n",
       "      <td>0.046712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.107635</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>-0.036582</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.173067</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.073846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>-0.018014</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.073120</td>\n",
       "      <td>-0.051948</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>-0.007939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.099033</td>\n",
       "      <td>-0.109059</td>\n",
       "      <td>-0.020829</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.179059</td>\n",
       "      <td>-0.068382</td>\n",
       "      <td>0.062943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>-0.036238</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.038809</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.014445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.265591</td>\n",
       "      <td>-0.619277</td>\n",
       "      <td>-0.279149</td>\n",
       "      <td>-0.187955</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>-0.135279</td>\n",
       "      <td>-0.067050</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>-0.159730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131376</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>-0.118500</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>-0.149491</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.486243</td>\n",
       "      <td>-0.482798</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>-0.156546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.141518</td>\n",
       "      <td>-0.191579</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>-0.059629</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>-0.095080</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>-0.057431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>-0.005974</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>-0.002152</td>\n",
       "      <td>0.008844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.877498</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>-0.127787</td>\n",
       "      <td>-0.066931</td>\n",
       "      <td>-0.135133</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.136196</td>\n",
       "      <td>-0.051518</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>-0.477439</td>\n",
       "      <td>-0.028659</td>\n",
       "      <td>0.204758</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>0.083038</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.005576</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>0.081172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.162111</td>\n",
       "      <td>-0.159106</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.021468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>-0.036101</td>\n",
       "      <td>-0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.199450</td>\n",
       "      <td>1.781264</td>\n",
       "      <td>-0.540263</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>0.331206</td>\n",
       "      <td>1.250888</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>-0.141133</td>\n",
       "      <td>-0.117322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>-0.128008</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.079405</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.038992</td>\n",
       "      <td>-0.088774</td>\n",
       "      <td>0.054421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.635700</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.237216</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>-0.166560</td>\n",
       "      <td>-0.074526</td>\n",
       "      <td>0.129139</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-0.380003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285796</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>-0.241631</td>\n",
       "      <td>0.065565</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>-0.085648</td>\n",
       "      <td>-0.044685</td>\n",
       "      <td>-0.053650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>-0.398007</td>\n",
       "      <td>0.607995</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>-0.024185</td>\n",
       "      <td>0.051853</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>0.352332</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.148656</td>\n",
       "      <td>-0.043532</td>\n",
       "      <td>-0.055591</td>\n",
       "      <td>-0.132109</td>\n",
       "      <td>-0.018838</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>0.041369</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.625380  0.034396 -0.672246  0.441779  0.159294 -0.598718   \n",
       "1           1 -1.107635 -0.008147 -0.036582 -0.227227 -0.173067  0.257546   \n",
       "2           2 -1.099033 -0.109059 -0.020829  0.007957 -0.059710  0.090729   \n",
       "3           3  0.265591 -0.619277 -0.279149 -0.187955  0.023135 -0.135279   \n",
       "4           4 -1.141518 -0.191579  0.005533 -0.059629  0.026487  0.013643   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.877498  0.236507 -0.127787 -0.066931 -0.135133  0.047662   \n",
       "5978     5978 -1.162111 -0.159106  0.019576  0.078777  0.026611 -0.007421   \n",
       "5979     5979  0.199450  1.781264 -0.540263  0.071173  0.331206  1.250888   \n",
       "5980     5980 -0.635700 -0.227858 -0.237216  0.009492 -0.166560 -0.074526   \n",
       "5981     5981 -0.674396 -0.398007  0.607995 -0.003883 -0.024185  0.051853   \n",
       "\n",
       "             6         7         8  ...       100       101       102  \\\n",
       "0     0.325886 -0.936302  0.305429  ... -0.143142  0.118564 -0.002334   \n",
       "1     0.036107 -0.059078 -0.073846  ...  0.030561 -0.018014  0.032755   \n",
       "2     0.179059 -0.068382  0.062943  ...  0.002262  0.035945 -0.017813   \n",
       "3    -0.067050  0.675716 -0.159730  ...  0.131376  0.064030 -0.118500   \n",
       "4    -0.095080  0.043151 -0.057431  ...  0.008822  0.004029  0.004533   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.136196 -0.051518 -0.006189  ...  0.100014 -0.477439 -0.028659   \n",
       "5978 -0.020261  0.025530 -0.021468  ...  0.005455  0.005500  0.013200   \n",
       "5979  0.351207 -0.141133 -0.117322  ...  0.100453  0.028486 -0.128008   \n",
       "5980  0.129139 -0.274902 -0.380003  ... -0.285796  0.651523  0.113559   \n",
       "5981  0.060919  0.352332  0.488067  ...  0.256775  0.148656 -0.043532   \n",
       "\n",
       "           103       104       105       106       107       108       109  \n",
       "0     0.089901 -0.111054 -0.021497  0.140365  0.117912 -0.126485  0.046712  \n",
       "1     0.015114  0.011464 -0.002095 -0.073120 -0.051948  0.005610 -0.007939  \n",
       "2    -0.008323 -0.036238  0.021623  0.038809  0.046284  0.007039  0.014445  \n",
       "3     0.066814 -0.149491 -0.003301  0.486243 -0.482798 -0.028555 -0.156546  \n",
       "4    -0.000862 -0.005974 -0.006765  0.007707  0.013415 -0.002152  0.008844  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.204758 -0.015639  0.083038  0.010453 -0.005576 -0.006840  0.081172  \n",
       "5978  0.006884  0.011396  0.006313 -0.050464 -0.032066 -0.036101 -0.007855  \n",
       "5979  0.088439 -0.112445 -0.079405  0.109667  0.038992 -0.088774  0.054421  \n",
       "5980 -0.241631  0.065565  0.000818 -0.040256 -0.085648 -0.044685 -0.053650  \n",
       "5981 -0.055591 -0.132109 -0.018838  0.036651  0.041369  0.035976 -0.103166  \n",
       "\n",
       "[5982 rows x 111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:16,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7337364470391993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:07<00:12,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7322073950514316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:11<00:07,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739314011676397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:15<00:03,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7167995899360579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:19<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358649569085349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 대분류 구매건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808812</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>-0.382530</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>-1.067826</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>-0.198159</td>\n",
       "      <td>-0.226099</td>\n",
       "      <td>-0.038080</td>\n",
       "      <td>0.324296</td>\n",
       "      <td>-0.434571</td>\n",
       "      <td>-0.308631</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>-0.018975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.942326</td>\n",
       "      <td>0.181016</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.165447</td>\n",
       "      <td>0.185474</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>-0.233817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035076</td>\n",
       "      <td>-0.147834</td>\n",
       "      <td>0.062239</td>\n",
       "      <td>0.060819</td>\n",
       "      <td>-0.054463</td>\n",
       "      <td>-0.387346</td>\n",
       "      <td>0.112056</td>\n",
       "      <td>-0.059185</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.030976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.939487</td>\n",
       "      <td>0.072728</td>\n",
       "      <td>-0.171136</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>-0.163384</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>-0.109646</td>\n",
       "      <td>0.098185</td>\n",
       "      <td>-0.189282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.047966</td>\n",
       "      <td>-0.038936</td>\n",
       "      <td>-0.112071</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.035366</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>0.039179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>-0.540114</td>\n",
       "      <td>-0.095850</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.377580</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>-0.019942</td>\n",
       "      <td>0.183439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>-0.014416</td>\n",
       "      <td>-0.061704</td>\n",
       "      <td>0.120444</td>\n",
       "      <td>-0.374014</td>\n",
       "      <td>0.177117</td>\n",
       "      <td>-0.243579</td>\n",
       "      <td>0.075744</td>\n",
       "      <td>-0.142311</td>\n",
       "      <td>-0.229687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.006475</td>\n",
       "      <td>-0.015659</td>\n",
       "      <td>0.083409</td>\n",
       "      <td>-0.036429</td>\n",
       "      <td>0.082568</td>\n",
       "      <td>-0.020770</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>-0.029358</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.040425</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.049531</td>\n",
       "      <td>-0.034650</td>\n",
       "      <td>-0.017044</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>0.021210</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.527805</td>\n",
       "      <td>0.460797</td>\n",
       "      <td>-0.064967</td>\n",
       "      <td>-0.029257</td>\n",
       "      <td>0.232430</td>\n",
       "      <td>-0.141500</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>-0.706434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477599</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.367133</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.424302</td>\n",
       "      <td>-0.089105</td>\n",
       "      <td>-0.048746</td>\n",
       "      <td>0.062714</td>\n",
       "      <td>-0.055811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.038196</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>-0.068062</td>\n",
       "      <td>-0.030968</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.158339</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>-0.045128</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>-0.058065</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>-0.046763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.672151</td>\n",
       "      <td>1.288926</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.442555</td>\n",
       "      <td>-0.225962</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>-0.542938</td>\n",
       "      <td>-0.306575</td>\n",
       "      <td>-0.724191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267473</td>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.246498</td>\n",
       "      <td>-0.123809</td>\n",
       "      <td>-0.203993</td>\n",
       "      <td>-0.005225</td>\n",
       "      <td>-0.029028</td>\n",
       "      <td>0.124641</td>\n",
       "      <td>0.155520</td>\n",
       "      <td>0.100988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.561052</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>-0.023670</td>\n",
       "      <td>0.353346</td>\n",
       "      <td>0.424770</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149904</td>\n",
       "      <td>-0.020741</td>\n",
       "      <td>-0.158265</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>-0.201403</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.567873</td>\n",
       "      <td>-0.410687</td>\n",
       "      <td>-0.080075</td>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.804268</td>\n",
       "      <td>-0.300905</td>\n",
       "      <td>-0.010156</td>\n",
       "      <td>0.041940</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.044154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064577</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>-0.091283</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.027214</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>0.156810</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.190463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.808812  0.047621 -0.382530  0.136842  0.068270 -1.067826   \n",
       "1           1 -0.942326  0.181016  0.039485  0.224548  0.165447  0.185474   \n",
       "2           2 -0.939487  0.072728 -0.171136  0.257513 -0.163384 -0.015842   \n",
       "3           3  0.176414 -0.540114 -0.095850  0.039596  0.054163  0.377580   \n",
       "4           4 -1.006475 -0.015659  0.083409 -0.036429  0.082568 -0.020770   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.527805  0.460797 -0.064967 -0.029257  0.232430 -0.141500   \n",
       "5978     5978 -1.038196  0.022598  0.023371 -0.003908  0.008111  0.030509   \n",
       "5979     5979  0.672151  1.288926  0.047105  0.442555 -0.225962  0.620944   \n",
       "5980     5980 -0.561052 -0.015907  0.100263  0.082922 -0.023670  0.353346   \n",
       "5981     5981 -0.804268 -0.300905 -0.010156  0.041940  0.061396  0.123361   \n",
       "\n",
       "             6         7         8  ...        25        26        27  \\\n",
       "0     0.097073  0.064659  0.123847  ...  0.278258 -0.198159 -0.226099   \n",
       "1     0.260437  0.067577 -0.233817  ... -0.035076 -0.147834  0.062239   \n",
       "2    -0.109646  0.098185 -0.189282  ...  0.057341  0.047966 -0.038936   \n",
       "3     0.169790 -0.019942  0.183439  ...  0.156863 -0.014416 -0.061704   \n",
       "4     0.012661 -0.029358  0.030033  ...  0.008659  0.040425 -0.007492   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.104384  0.065651 -0.706434  ... -0.477599  0.215720  0.023805   \n",
       "5978 -0.068062 -0.030968  0.011029  ...  0.106910  0.017061  0.158339   \n",
       "5979 -0.542938 -0.306575 -0.724191  ... -0.267473  0.172990  0.246498   \n",
       "5980  0.424770 -0.039177  0.215357  ...  0.149904 -0.020741 -0.158265   \n",
       "5981 -0.009046 -0.017363 -0.044154  ... -0.064577  0.030567 -0.091283   \n",
       "\n",
       "            28        29        30        31        32        33        34  \n",
       "0    -0.038080  0.324296 -0.434571 -0.308631 -0.016363  0.194200 -0.018975  \n",
       "1     0.060819 -0.054463 -0.387346  0.112056 -0.059185  0.006323 -0.030976  \n",
       "2    -0.112071 -0.006490  0.062245 -0.004990  0.035366  0.044459  0.039179  \n",
       "3     0.120444 -0.374014  0.177117 -0.243579  0.075744 -0.142311 -0.229687  \n",
       "4     0.042274  0.049531 -0.034650 -0.017044 -0.018064  0.021210 -0.000362  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.367133  0.026163  0.424302 -0.089105 -0.048746  0.062714 -0.055811  \n",
       "5978 -0.014808 -0.045128  0.014905 -0.012643 -0.058065  0.033216 -0.046763  \n",
       "5979 -0.123809 -0.203993 -0.005225 -0.029028  0.124641  0.155520  0.100988  \n",
       "5980  0.161862 -0.201403 -0.103223 -0.567873 -0.410687 -0.080075  0.002968  \n",
       "5981  0.040444  0.000616 -0.027214 -0.019029  0.156810  0.123323  0.190463  \n",
       "\n",
       "[5982 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "seed = 2020\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:03<00:14,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7358171740339171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:07<00:10,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7350135529608006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:11<00:07,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343880316930775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:14<00:03,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7309911036975257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:19<00:00,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192104531554073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 중분류 구매여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.031835</td>\n",
       "      <td>0.212301</td>\n",
       "      <td>-0.922307</td>\n",
       "      <td>-0.869803</td>\n",
       "      <td>-0.305008</td>\n",
       "      <td>0.092058</td>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.575745</td>\n",
       "      <td>-0.703853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102421</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>-0.375416</td>\n",
       "      <td>-0.050509</td>\n",
       "      <td>0.185363</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-0.122237</td>\n",
       "      <td>-0.086713</td>\n",
       "      <td>-0.053711</td>\n",
       "      <td>-0.077012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.545397</td>\n",
       "      <td>-0.120407</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.202452</td>\n",
       "      <td>0.264835</td>\n",
       "      <td>0.240070</td>\n",
       "      <td>0.129344</td>\n",
       "      <td>0.058812</td>\n",
       "      <td>0.209729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.074902</td>\n",
       "      <td>0.029886</td>\n",
       "      <td>0.116798</td>\n",
       "      <td>-0.031030</td>\n",
       "      <td>-0.049614</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.006372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.415123</td>\n",
       "      <td>-0.065534</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>-0.016653</td>\n",
       "      <td>0.142608</td>\n",
       "      <td>0.400511</td>\n",
       "      <td>-0.053878</td>\n",
       "      <td>-0.125965</td>\n",
       "      <td>-0.270389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.020539</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.003550</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.015099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.865498</td>\n",
       "      <td>-1.222110</td>\n",
       "      <td>-0.553205</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.309707</td>\n",
       "      <td>-0.115284</td>\n",
       "      <td>-0.423851</td>\n",
       "      <td>0.164560</td>\n",
       "      <td>0.401825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>-0.141897</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>-0.023132</td>\n",
       "      <td>0.142257</td>\n",
       "      <td>0.325156</td>\n",
       "      <td>0.171970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-0.078229</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>0.219325</td>\n",
       "      <td>-0.030194</td>\n",
       "      <td>-0.500378</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>-0.016312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>-0.006011</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>-0.018732</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.004584</td>\n",
       "      <td>-0.006360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-1.161452</td>\n",
       "      <td>0.308622</td>\n",
       "      <td>-0.139144</td>\n",
       "      <td>-0.117040</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>-0.058142</td>\n",
       "      <td>-0.208458</td>\n",
       "      <td>-0.120671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>-0.135064</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>-0.209229</td>\n",
       "      <td>-0.247969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.547982</td>\n",
       "      <td>-0.166368</td>\n",
       "      <td>0.062790</td>\n",
       "      <td>-0.058637</td>\n",
       "      <td>-0.039730</td>\n",
       "      <td>0.145217</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017176</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.003491</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>-0.008849</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.011166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.204833</td>\n",
       "      <td>1.663809</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>0.605944</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>1.091609</td>\n",
       "      <td>-0.392112</td>\n",
       "      <td>1.131950</td>\n",
       "      <td>-0.592724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523407</td>\n",
       "      <td>0.207549</td>\n",
       "      <td>-0.355611</td>\n",
       "      <td>-0.084467</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>-0.044070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.925491</td>\n",
       "      <td>-0.298534</td>\n",
       "      <td>-0.188338</td>\n",
       "      <td>-0.024190</td>\n",
       "      <td>0.231828</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.755301</td>\n",
       "      <td>-0.127350</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028420</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>-0.130566</td>\n",
       "      <td>0.075247</td>\n",
       "      <td>-0.050180</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>-0.168739</td>\n",
       "      <td>-0.393781</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.392946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.512350</td>\n",
       "      <td>-0.620099</td>\n",
       "      <td>0.938312</td>\n",
       "      <td>-0.100132</td>\n",
       "      <td>-0.191828</td>\n",
       "      <td>0.116272</td>\n",
       "      <td>-0.882415</td>\n",
       "      <td>-0.106105</td>\n",
       "      <td>-0.051885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>-0.151601</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>-0.214053</td>\n",
       "      <td>-0.182360</td>\n",
       "      <td>0.173993</td>\n",
       "      <td>0.166463</td>\n",
       "      <td>0.261078</td>\n",
       "      <td>0.370338</td>\n",
       "      <td>0.349272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.031835  0.212301 -0.922307 -0.869803 -0.305008  0.092058   \n",
       "1           1 -1.545397 -0.120407  0.028675  0.202452  0.264835  0.240070   \n",
       "2           2 -1.415123 -0.065534  0.005330 -0.016653  0.142608  0.400511   \n",
       "3           3  0.865498 -1.222110 -0.553205  0.022980  0.309707 -0.115284   \n",
       "4           4 -1.341069 -0.078229 -0.045112  0.219325 -0.030194 -0.500378   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -1.161452  0.308622 -0.139144 -0.117040  0.072620  0.152300   \n",
       "5978     5978 -1.547982 -0.166368  0.062790 -0.058637 -0.039730  0.145217   \n",
       "5979     5979  0.204833  1.663809 -0.728419  0.605944  0.811258  1.091609   \n",
       "5980     5980 -0.925491 -0.298534 -0.188338 -0.024190  0.231828  0.287504   \n",
       "5981     5981 -0.512350 -0.620099  0.938312 -0.100132 -0.191828  0.116272   \n",
       "\n",
       "             6         7         8  ...       101       102       103  \\\n",
       "0     0.831769 -0.575745 -0.703853  ...  0.102421 -0.318619 -0.375416   \n",
       "1     0.129344  0.058812  0.209729  ...  0.028266  0.074902  0.029886   \n",
       "2    -0.053878 -0.125965 -0.270389  ...  0.018800  0.036842 -0.011082   \n",
       "3    -0.423851  0.164560  0.401825  ...  0.122099  0.050478  0.119724   \n",
       "4     0.017921  0.145940 -0.016312  ...  0.012135  0.031032 -0.017324   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977 -0.058142 -0.208458 -0.120671  ...  0.004387 -0.135064  0.031170   \n",
       "5978  0.182716  0.213168  0.241474  ... -0.017176 -0.011808 -0.000613   \n",
       "5979 -0.392112  1.131950 -0.592724  ... -0.523407  0.207549 -0.355611   \n",
       "5980  0.755301 -0.127350  0.329944  ... -0.028420 -0.098941 -0.130566   \n",
       "5981 -0.882415 -0.106105 -0.051885  ...  0.065957 -0.151601  0.072650   \n",
       "\n",
       "           104       105       106       107       108       109       110  \n",
       "0    -0.050509  0.185363 -0.019726 -0.122237 -0.086713 -0.053711 -0.077012  \n",
       "1     0.116798 -0.031030 -0.049614  0.024517  0.003476  0.001157  0.006372  \n",
       "2    -0.020539 -0.010853 -0.012236 -0.003550 -0.000766  0.007166  0.015099  \n",
       "3    -0.141897 -0.014390  0.095265 -0.023132  0.142257  0.325156  0.171970  \n",
       "4    -0.006011  0.007325 -0.018732  0.004144 -0.010431 -0.004584 -0.006360  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.002395 -0.009385  0.033274  0.079296  0.230744 -0.209229 -0.247969  \n",
       "5978 -0.003491 -0.025970 -0.001241  0.008654 -0.008849 -0.015761 -0.011166  \n",
       "5979 -0.084467  0.018351  0.011924  0.144681  0.012927  0.108045 -0.044070  \n",
       "5980  0.075247 -0.050180  0.088172 -0.168739 -0.393781  0.228118  0.392946  \n",
       "5981 -0.214053 -0.182360  0.173993  0.166463  0.261078  0.370338  0.349272  \n",
       "\n",
       "[5982 rows x 112 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:16,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7081856408117877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:08<00:12,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7055662705031971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:12<00:08,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7239583333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:17<00:04,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7370725604670558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7215822212955241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 대분류 구매여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.436058</td>\n",
       "      <td>-0.040728</td>\n",
       "      <td>-0.376852</td>\n",
       "      <td>0.244498</td>\n",
       "      <td>-0.337669</td>\n",
       "      <td>0.594535</td>\n",
       "      <td>1.160821</td>\n",
       "      <td>-0.507886</td>\n",
       "      <td>-0.026341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371315</td>\n",
       "      <td>-0.820841</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.359050</td>\n",
       "      <td>-0.052447</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>-0.028469</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.103598</td>\n",
       "      <td>0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.495079</td>\n",
       "      <td>0.426246</td>\n",
       "      <td>0.603980</td>\n",
       "      <td>0.267780</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>-0.341812</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>-0.268278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027723</td>\n",
       "      <td>-0.408299</td>\n",
       "      <td>-0.796369</td>\n",
       "      <td>-0.191770</td>\n",
       "      <td>0.136208</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>-0.027328</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>-0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.486196</td>\n",
       "      <td>0.137751</td>\n",
       "      <td>0.094870</td>\n",
       "      <td>0.455594</td>\n",
       "      <td>0.025952</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.156926</td>\n",
       "      <td>-0.156983</td>\n",
       "      <td>-0.082030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102234</td>\n",
       "      <td>0.202870</td>\n",
       "      <td>0.137714</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>-0.046748</td>\n",
       "      <td>-0.249884</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>-0.040493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.826307</td>\n",
       "      <td>-0.968225</td>\n",
       "      <td>0.253546</td>\n",
       "      <td>0.553680</td>\n",
       "      <td>-0.338130</td>\n",
       "      <td>-0.531447</td>\n",
       "      <td>-0.663852</td>\n",
       "      <td>0.274229</td>\n",
       "      <td>0.311605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615561</td>\n",
       "      <td>0.226854</td>\n",
       "      <td>0.448593</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-0.397996</td>\n",
       "      <td>-0.505601</td>\n",
       "      <td>-0.206288</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>-0.078507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.388948</td>\n",
       "      <td>0.099101</td>\n",
       "      <td>0.054519</td>\n",
       "      <td>-0.485316</td>\n",
       "      <td>-0.493745</td>\n",
       "      <td>0.040495</td>\n",
       "      <td>0.094735</td>\n",
       "      <td>-0.274916</td>\n",
       "      <td>-0.333733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094130</td>\n",
       "      <td>0.096581</td>\n",
       "      <td>-0.122793</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>-0.033616</td>\n",
       "      <td>0.010124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.758481</td>\n",
       "      <td>0.812565</td>\n",
       "      <td>-0.108292</td>\n",
       "      <td>0.172876</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>-0.143411</td>\n",
       "      <td>0.183231</td>\n",
       "      <td>0.159825</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780837</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.534725</td>\n",
       "      <td>-0.266745</td>\n",
       "      <td>-0.442471</td>\n",
       "      <td>-0.236793</td>\n",
       "      <td>-0.081901</td>\n",
       "      <td>0.159949</td>\n",
       "      <td>-0.030645</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.564872</td>\n",
       "      <td>0.227113</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>0.254983</td>\n",
       "      <td>-0.491875</td>\n",
       "      <td>-0.342264</td>\n",
       "      <td>0.369359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097276</td>\n",
       "      <td>-0.100308</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.034280</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>1.010739</td>\n",
       "      <td>1.482501</td>\n",
       "      <td>1.119399</td>\n",
       "      <td>0.718032</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>0.340607</td>\n",
       "      <td>-0.337983</td>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.405145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111127</td>\n",
       "      <td>0.135636</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.729023</td>\n",
       "      <td>-0.262131</td>\n",
       "      <td>0.856770</td>\n",
       "      <td>0.272822</td>\n",
       "      <td>0.424178</td>\n",
       "      <td>-0.637153</td>\n",
       "      <td>-0.439690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.907570</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.415867</td>\n",
       "      <td>-0.849732</td>\n",
       "      <td>0.382268</td>\n",
       "      <td>-0.345673</td>\n",
       "      <td>0.521682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653179</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>-0.030792</td>\n",
       "      <td>-0.207601</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.046550</td>\n",
       "      <td>-0.100628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.916461</td>\n",
       "      <td>-0.791022</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.219709</td>\n",
       "      <td>-0.125223</td>\n",
       "      <td>0.073441</td>\n",
       "      <td>-0.344049</td>\n",
       "      <td>0.796474</td>\n",
       "      <td>-0.018890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057549</td>\n",
       "      <td>-0.350444</td>\n",
       "      <td>-0.070858</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>-0.310068</td>\n",
       "      <td>-0.501102</td>\n",
       "      <td>0.272890</td>\n",
       "      <td>0.247785</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.436058 -0.040728 -0.376852  0.244498 -0.337669  0.594535   \n",
       "1           1 -1.495079  0.426246  0.603980  0.267780  0.167863 -0.341812   \n",
       "2           2 -1.486196  0.137751  0.094870  0.455594  0.025952  0.268160   \n",
       "3           3  0.826307 -0.968225  0.253546  0.553680 -0.338130 -0.531447   \n",
       "4           4 -1.388948  0.099101  0.054519 -0.485316 -0.493745  0.040495   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.758481  0.812565 -0.108292  0.172876  0.196507 -0.143411   \n",
       "5978     5978 -1.564872  0.227113  0.097719  0.005096 -0.014250  0.254983   \n",
       "5979     5979  1.010739  1.482501  1.119399  0.718032 -0.021002  0.340607   \n",
       "5980     5980 -0.907570  0.014547  0.360717  0.103525  0.415867 -0.849732   \n",
       "5981     5981 -0.916461 -0.791022  0.136646  0.219709 -0.125223  0.073441   \n",
       "\n",
       "             6         7         8  ...        26        27        28  \\\n",
       "0     1.160821 -0.507886 -0.026341  ...  0.371315 -0.820841  0.280656   \n",
       "1     0.074077  0.082130 -0.268278  ... -0.027723 -0.408299 -0.796369   \n",
       "2     0.156926 -0.156983 -0.082030  ...  0.102234  0.202870  0.137714   \n",
       "3    -0.663852  0.274229  0.311605  ... -0.615561  0.226854  0.448593   \n",
       "4     0.094735 -0.274916 -0.333733  ...  0.094130  0.096581 -0.122793   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.183231  0.159825 -0.234539  ... -0.780837 -0.074323 -0.534725   \n",
       "5978 -0.491875 -0.342264  0.369359  ... -0.097276 -0.100308  0.012817   \n",
       "5979 -0.337983  0.478843  0.405145  ...  0.111127  0.135636 -0.055767   \n",
       "5980  0.382268 -0.345673  0.521682  ... -0.653179  0.014776  0.284553   \n",
       "5981 -0.344049  0.796474 -0.018890  ... -0.057549 -0.350444 -0.070858   \n",
       "\n",
       "            29        30        31        32        33        34        35  \n",
       "0     0.359050 -0.052447  0.167750 -0.028469  0.045124  0.103598  0.014635  \n",
       "1    -0.191770  0.136208  0.175161 -0.027328  0.023678  0.019509 -0.013586  \n",
       "2     0.092741 -0.046748 -0.249884  0.133006  0.062282 -0.045456 -0.040493  \n",
       "3     0.001418 -0.397996 -0.505601 -0.206288 -0.023323 -0.058132 -0.078507  \n",
       "4     0.078391 -0.059339 -0.210875  0.119112  0.095087 -0.033616  0.010124  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.266745 -0.442471 -0.236793 -0.081901  0.159949 -0.030645  0.010190  \n",
       "5978  0.030391  0.023927  0.100438 -0.032773 -0.034280 -0.015645  0.006128  \n",
       "5979 -0.729023 -0.262131  0.856770  0.272822  0.424178 -0.637153 -0.439690  \n",
       "5980 -0.030792 -0.207601 -0.053542 -0.043660 -0.118073 -0.046550 -0.100628  \n",
       "5981  0.011655 -0.310068 -0.501102  0.272890  0.247785 -0.007448  0.010920  \n",
       "\n",
       "[5982 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:18,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744887232415902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:09<00:14,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7475717611898804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:15<00:09,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7447742910758965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:19<00:04,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7392314776202391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:23<00:00,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7458472338059494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 중분류 & 대분류 구매건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625380</td>\n",
       "      <td>0.034396</td>\n",
       "      <td>-0.672246</td>\n",
       "      <td>0.441779</td>\n",
       "      <td>0.159294</td>\n",
       "      <td>-0.598718</td>\n",
       "      <td>0.325886</td>\n",
       "      <td>-0.936302</td>\n",
       "      <td>0.305429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143142</td>\n",
       "      <td>0.118564</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.089901</td>\n",
       "      <td>-0.111054</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>0.140365</td>\n",
       "      <td>0.117912</td>\n",
       "      <td>-0.126485</td>\n",
       "      <td>0.046712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.107635</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>-0.036582</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.173067</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.073846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>-0.018014</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.073120</td>\n",
       "      <td>-0.051948</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>-0.007939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.099033</td>\n",
       "      <td>-0.109059</td>\n",
       "      <td>-0.020829</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.179059</td>\n",
       "      <td>-0.068382</td>\n",
       "      <td>0.062943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>-0.036238</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.038809</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.014445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.265591</td>\n",
       "      <td>-0.619277</td>\n",
       "      <td>-0.279149</td>\n",
       "      <td>-0.187955</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>-0.135279</td>\n",
       "      <td>-0.067050</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>-0.159730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131376</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>-0.118500</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>-0.149491</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.486243</td>\n",
       "      <td>-0.482798</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>-0.156546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.141518</td>\n",
       "      <td>-0.191579</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>-0.059629</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>-0.095080</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>-0.057431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>-0.005974</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>-0.002152</td>\n",
       "      <td>0.008844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.877498</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>-0.127787</td>\n",
       "      <td>-0.066931</td>\n",
       "      <td>-0.135133</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.136196</td>\n",
       "      <td>-0.051518</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>-0.477439</td>\n",
       "      <td>-0.028659</td>\n",
       "      <td>0.204758</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>0.083038</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.005576</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>0.081172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.162111</td>\n",
       "      <td>-0.159106</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.021468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>-0.036101</td>\n",
       "      <td>-0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.199450</td>\n",
       "      <td>1.781264</td>\n",
       "      <td>-0.540263</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>0.331206</td>\n",
       "      <td>1.250888</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>-0.141133</td>\n",
       "      <td>-0.117322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>-0.128008</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.079405</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.038992</td>\n",
       "      <td>-0.088774</td>\n",
       "      <td>0.054421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.635700</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.237216</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>-0.166560</td>\n",
       "      <td>-0.074526</td>\n",
       "      <td>0.129139</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-0.380003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285796</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>-0.241631</td>\n",
       "      <td>0.065565</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>-0.085648</td>\n",
       "      <td>-0.044685</td>\n",
       "      <td>-0.053650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>-0.398007</td>\n",
       "      <td>0.607995</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>-0.024185</td>\n",
       "      <td>0.051853</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>0.352332</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.148656</td>\n",
       "      <td>-0.043532</td>\n",
       "      <td>-0.055591</td>\n",
       "      <td>-0.132109</td>\n",
       "      <td>-0.018838</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>0.041369</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.625380  0.034396 -0.672246  0.441779  0.159294 -0.598718   \n",
       "1           1 -1.107635 -0.008147 -0.036582 -0.227227 -0.173067  0.257546   \n",
       "2           2 -1.099033 -0.109059 -0.020829  0.007957 -0.059710  0.090729   \n",
       "3           3  0.265591 -0.619277 -0.279149 -0.187955  0.023135 -0.135279   \n",
       "4           4 -1.141518 -0.191579  0.005533 -0.059629  0.026487  0.013643   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.877498  0.236507 -0.127787 -0.066931 -0.135133  0.047662   \n",
       "5978     5978 -1.162111 -0.159106  0.019576  0.078777  0.026611 -0.007421   \n",
       "5979     5979  0.199450  1.781264 -0.540263  0.071173  0.331206  1.250888   \n",
       "5980     5980 -0.635700 -0.227858 -0.237216  0.009492 -0.166560 -0.074526   \n",
       "5981     5981 -0.674396 -0.398007  0.607995 -0.003883 -0.024185  0.051853   \n",
       "\n",
       "             6         7         8  ...       100       101       102  \\\n",
       "0     0.325886 -0.936302  0.305429  ... -0.143142  0.118564 -0.002334   \n",
       "1     0.036107 -0.059078 -0.073846  ...  0.030561 -0.018014  0.032755   \n",
       "2     0.179059 -0.068382  0.062943  ...  0.002262  0.035945 -0.017813   \n",
       "3    -0.067050  0.675716 -0.159730  ...  0.131376  0.064030 -0.118500   \n",
       "4    -0.095080  0.043151 -0.057431  ...  0.008822  0.004029  0.004533   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.136196 -0.051518 -0.006189  ...  0.100014 -0.477439 -0.028659   \n",
       "5978 -0.020261  0.025530 -0.021468  ...  0.005455  0.005500  0.013200   \n",
       "5979  0.351207 -0.141133 -0.117322  ...  0.100453  0.028486 -0.128008   \n",
       "5980  0.129139 -0.274902 -0.380003  ... -0.285796  0.651523  0.113559   \n",
       "5981  0.060919  0.352332  0.488067  ...  0.256775  0.148656 -0.043532   \n",
       "\n",
       "           103       104       105       106       107       108       109  \n",
       "0     0.089901 -0.111054 -0.021497  0.140365  0.117912 -0.126485  0.046712  \n",
       "1     0.015114  0.011464 -0.002095 -0.073120 -0.051948  0.005610 -0.007939  \n",
       "2    -0.008323 -0.036238  0.021623  0.038809  0.046284  0.007039  0.014445  \n",
       "3     0.066814 -0.149491 -0.003301  0.486243 -0.482798 -0.028555 -0.156546  \n",
       "4    -0.000862 -0.005974 -0.006765  0.007707  0.013415 -0.002152  0.008844  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.204758 -0.015639  0.083038  0.010453 -0.005576 -0.006840  0.081172  \n",
       "5978  0.006884  0.011396  0.006313 -0.050464 -0.032066 -0.036101 -0.007855  \n",
       "5979  0.088439 -0.112445 -0.079405  0.109667  0.038992 -0.088774  0.054421  \n",
       "5980 -0.241631  0.065565  0.000818 -0.040256 -0.085648 -0.044685 -0.053650  \n",
       "5981 -0.055591 -0.132109 -0.018838  0.036651  0.041369  0.035976 -0.103166  \n",
       "\n",
       "[5982 rows x 111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808812</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>-0.382530</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>-1.067826</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>-0.198159</td>\n",
       "      <td>-0.226099</td>\n",
       "      <td>-0.038080</td>\n",
       "      <td>0.324296</td>\n",
       "      <td>-0.434571</td>\n",
       "      <td>-0.308631</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>-0.018975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.942326</td>\n",
       "      <td>0.181016</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.165447</td>\n",
       "      <td>0.185474</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>-0.233817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035076</td>\n",
       "      <td>-0.147834</td>\n",
       "      <td>0.062239</td>\n",
       "      <td>0.060819</td>\n",
       "      <td>-0.054463</td>\n",
       "      <td>-0.387346</td>\n",
       "      <td>0.112056</td>\n",
       "      <td>-0.059185</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.030976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.939487</td>\n",
       "      <td>0.072728</td>\n",
       "      <td>-0.171136</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>-0.163384</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>-0.109646</td>\n",
       "      <td>0.098185</td>\n",
       "      <td>-0.189282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.047966</td>\n",
       "      <td>-0.038936</td>\n",
       "      <td>-0.112071</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.035366</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>0.039179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>-0.540114</td>\n",
       "      <td>-0.095850</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.377580</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>-0.019942</td>\n",
       "      <td>0.183439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>-0.014416</td>\n",
       "      <td>-0.061704</td>\n",
       "      <td>0.120444</td>\n",
       "      <td>-0.374014</td>\n",
       "      <td>0.177117</td>\n",
       "      <td>-0.243579</td>\n",
       "      <td>0.075744</td>\n",
       "      <td>-0.142311</td>\n",
       "      <td>-0.229687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.006475</td>\n",
       "      <td>-0.015659</td>\n",
       "      <td>0.083409</td>\n",
       "      <td>-0.036429</td>\n",
       "      <td>0.082568</td>\n",
       "      <td>-0.020770</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>-0.029358</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.040425</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.049531</td>\n",
       "      <td>-0.034650</td>\n",
       "      <td>-0.017044</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>0.021210</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.527805</td>\n",
       "      <td>0.460797</td>\n",
       "      <td>-0.064967</td>\n",
       "      <td>-0.029257</td>\n",
       "      <td>0.232430</td>\n",
       "      <td>-0.141500</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>-0.706434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477599</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.367133</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.424302</td>\n",
       "      <td>-0.089105</td>\n",
       "      <td>-0.048746</td>\n",
       "      <td>0.062714</td>\n",
       "      <td>-0.055811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.038196</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>-0.068062</td>\n",
       "      <td>-0.030968</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.158339</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>-0.045128</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>-0.058065</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>-0.046763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.672151</td>\n",
       "      <td>1.288926</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.442555</td>\n",
       "      <td>-0.225962</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>-0.542938</td>\n",
       "      <td>-0.306575</td>\n",
       "      <td>-0.724191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267473</td>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.246498</td>\n",
       "      <td>-0.123809</td>\n",
       "      <td>-0.203993</td>\n",
       "      <td>-0.005225</td>\n",
       "      <td>-0.029028</td>\n",
       "      <td>0.124641</td>\n",
       "      <td>0.155520</td>\n",
       "      <td>0.100988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.561052</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>-0.023670</td>\n",
       "      <td>0.353346</td>\n",
       "      <td>0.424770</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149904</td>\n",
       "      <td>-0.020741</td>\n",
       "      <td>-0.158265</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>-0.201403</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.567873</td>\n",
       "      <td>-0.410687</td>\n",
       "      <td>-0.080075</td>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.804268</td>\n",
       "      <td>-0.300905</td>\n",
       "      <td>-0.010156</td>\n",
       "      <td>0.041940</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.044154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064577</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>-0.091283</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.027214</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>0.156810</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.190463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.808812  0.047621 -0.382530  0.136842  0.068270 -1.067826   \n",
       "1           1 -0.942326  0.181016  0.039485  0.224548  0.165447  0.185474   \n",
       "2           2 -0.939487  0.072728 -0.171136  0.257513 -0.163384 -0.015842   \n",
       "3           3  0.176414 -0.540114 -0.095850  0.039596  0.054163  0.377580   \n",
       "4           4 -1.006475 -0.015659  0.083409 -0.036429  0.082568 -0.020770   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.527805  0.460797 -0.064967 -0.029257  0.232430 -0.141500   \n",
       "5978     5978 -1.038196  0.022598  0.023371 -0.003908  0.008111  0.030509   \n",
       "5979     5979  0.672151  1.288926  0.047105  0.442555 -0.225962  0.620944   \n",
       "5980     5980 -0.561052 -0.015907  0.100263  0.082922 -0.023670  0.353346   \n",
       "5981     5981 -0.804268 -0.300905 -0.010156  0.041940  0.061396  0.123361   \n",
       "\n",
       "             6         7         8  ...        25        26        27  \\\n",
       "0     0.097073  0.064659  0.123847  ...  0.278258 -0.198159 -0.226099   \n",
       "1     0.260437  0.067577 -0.233817  ... -0.035076 -0.147834  0.062239   \n",
       "2    -0.109646  0.098185 -0.189282  ...  0.057341  0.047966 -0.038936   \n",
       "3     0.169790 -0.019942  0.183439  ...  0.156863 -0.014416 -0.061704   \n",
       "4     0.012661 -0.029358  0.030033  ...  0.008659  0.040425 -0.007492   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.104384  0.065651 -0.706434  ... -0.477599  0.215720  0.023805   \n",
       "5978 -0.068062 -0.030968  0.011029  ...  0.106910  0.017061  0.158339   \n",
       "5979 -0.542938 -0.306575 -0.724191  ... -0.267473  0.172990  0.246498   \n",
       "5980  0.424770 -0.039177  0.215357  ...  0.149904 -0.020741 -0.158265   \n",
       "5981 -0.009046 -0.017363 -0.044154  ... -0.064577  0.030567 -0.091283   \n",
       "\n",
       "            28        29        30        31        32        33        34  \n",
       "0    -0.038080  0.324296 -0.434571 -0.308631 -0.016363  0.194200 -0.018975  \n",
       "1     0.060819 -0.054463 -0.387346  0.112056 -0.059185  0.006323 -0.030976  \n",
       "2    -0.112071 -0.006490  0.062245 -0.004990  0.035366  0.044459  0.039179  \n",
       "3     0.120444 -0.374014  0.177117 -0.243579  0.075744 -0.142311 -0.229687  \n",
       "4     0.042274  0.049531 -0.034650 -0.017044 -0.018064  0.021210 -0.000362  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.367133  0.026163  0.424302 -0.089105 -0.048746  0.062714 -0.055811  \n",
       "5978 -0.014808 -0.045128  0.014905 -0.012643 -0.058065  0.033216 -0.046763  \n",
       "5979 -0.123809 -0.203993 -0.005225 -0.029028  0.124641  0.155520  0.100988  \n",
       "5980  0.161862 -0.201403 -0.103223 -0.567873 -0.410687 -0.080075  0.002968  \n",
       "5981  0.040444  0.000616 -0.027214 -0.019029  0.156810  0.123323  0.190463  \n",
       "\n",
       "[5982 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_nm = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_nm = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_mclas = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_mclas = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "### 중분류 구매건수 nm과 대분류 구매건수 mclas를 합친다\n",
    "\n",
    "X_train = pd.concat([X_train_nm, X_train_mclas], axis=1)\n",
    "X_test = pd.concat([X_test_nm, X_test_mclas], axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:03<00:14,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7352046844592716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:07<00:11,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742120169585766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:12<00:08,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7158135251598554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:17<00:04,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7363036905754796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:22<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.741203607172644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 중분류 & 대분류 구매여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.031835</td>\n",
       "      <td>0.212301</td>\n",
       "      <td>-0.922307</td>\n",
       "      <td>-0.869803</td>\n",
       "      <td>-0.305008</td>\n",
       "      <td>0.092058</td>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.575745</td>\n",
       "      <td>-0.703853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102421</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>-0.375416</td>\n",
       "      <td>-0.050509</td>\n",
       "      <td>0.185363</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-0.122237</td>\n",
       "      <td>-0.086713</td>\n",
       "      <td>-0.053711</td>\n",
       "      <td>-0.077012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.545397</td>\n",
       "      <td>-0.120407</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.202452</td>\n",
       "      <td>0.264835</td>\n",
       "      <td>0.240070</td>\n",
       "      <td>0.129344</td>\n",
       "      <td>0.058812</td>\n",
       "      <td>0.209729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.074902</td>\n",
       "      <td>0.029886</td>\n",
       "      <td>0.116798</td>\n",
       "      <td>-0.031030</td>\n",
       "      <td>-0.049614</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.006372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.415123</td>\n",
       "      <td>-0.065534</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>-0.016653</td>\n",
       "      <td>0.142608</td>\n",
       "      <td>0.400511</td>\n",
       "      <td>-0.053878</td>\n",
       "      <td>-0.125965</td>\n",
       "      <td>-0.270389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.020539</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.003550</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.015099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.865498</td>\n",
       "      <td>-1.222110</td>\n",
       "      <td>-0.553205</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.309707</td>\n",
       "      <td>-0.115284</td>\n",
       "      <td>-0.423851</td>\n",
       "      <td>0.164560</td>\n",
       "      <td>0.401825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>-0.141897</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>-0.023132</td>\n",
       "      <td>0.142257</td>\n",
       "      <td>0.325156</td>\n",
       "      <td>0.171970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-0.078229</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>0.219325</td>\n",
       "      <td>-0.030194</td>\n",
       "      <td>-0.500378</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>-0.016312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>-0.006011</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>-0.018732</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.004584</td>\n",
       "      <td>-0.006360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-1.161452</td>\n",
       "      <td>0.308622</td>\n",
       "      <td>-0.139144</td>\n",
       "      <td>-0.117040</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>-0.058142</td>\n",
       "      <td>-0.208458</td>\n",
       "      <td>-0.120671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>-0.135064</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>-0.209229</td>\n",
       "      <td>-0.247969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.547982</td>\n",
       "      <td>-0.166368</td>\n",
       "      <td>0.062790</td>\n",
       "      <td>-0.058637</td>\n",
       "      <td>-0.039730</td>\n",
       "      <td>0.145217</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017176</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.003491</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>-0.008849</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.011166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.204833</td>\n",
       "      <td>1.663809</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>0.605944</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>1.091609</td>\n",
       "      <td>-0.392112</td>\n",
       "      <td>1.131950</td>\n",
       "      <td>-0.592724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523407</td>\n",
       "      <td>0.207549</td>\n",
       "      <td>-0.355611</td>\n",
       "      <td>-0.084467</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>-0.044070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.925491</td>\n",
       "      <td>-0.298534</td>\n",
       "      <td>-0.188338</td>\n",
       "      <td>-0.024190</td>\n",
       "      <td>0.231828</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.755301</td>\n",
       "      <td>-0.127350</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028420</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>-0.130566</td>\n",
       "      <td>0.075247</td>\n",
       "      <td>-0.050180</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>-0.168739</td>\n",
       "      <td>-0.393781</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.392946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.512350</td>\n",
       "      <td>-0.620099</td>\n",
       "      <td>0.938312</td>\n",
       "      <td>-0.100132</td>\n",
       "      <td>-0.191828</td>\n",
       "      <td>0.116272</td>\n",
       "      <td>-0.882415</td>\n",
       "      <td>-0.106105</td>\n",
       "      <td>-0.051885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>-0.151601</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>-0.214053</td>\n",
       "      <td>-0.182360</td>\n",
       "      <td>0.173993</td>\n",
       "      <td>0.166463</td>\n",
       "      <td>0.261078</td>\n",
       "      <td>0.370338</td>\n",
       "      <td>0.349272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.031835  0.212301 -0.922307 -0.869803 -0.305008  0.092058   \n",
       "1           1 -1.545397 -0.120407  0.028675  0.202452  0.264835  0.240070   \n",
       "2           2 -1.415123 -0.065534  0.005330 -0.016653  0.142608  0.400511   \n",
       "3           3  0.865498 -1.222110 -0.553205  0.022980  0.309707 -0.115284   \n",
       "4           4 -1.341069 -0.078229 -0.045112  0.219325 -0.030194 -0.500378   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -1.161452  0.308622 -0.139144 -0.117040  0.072620  0.152300   \n",
       "5978     5978 -1.547982 -0.166368  0.062790 -0.058637 -0.039730  0.145217   \n",
       "5979     5979  0.204833  1.663809 -0.728419  0.605944  0.811258  1.091609   \n",
       "5980     5980 -0.925491 -0.298534 -0.188338 -0.024190  0.231828  0.287504   \n",
       "5981     5981 -0.512350 -0.620099  0.938312 -0.100132 -0.191828  0.116272   \n",
       "\n",
       "             6         7         8  ...       101       102       103  \\\n",
       "0     0.831769 -0.575745 -0.703853  ...  0.102421 -0.318619 -0.375416   \n",
       "1     0.129344  0.058812  0.209729  ...  0.028266  0.074902  0.029886   \n",
       "2    -0.053878 -0.125965 -0.270389  ...  0.018800  0.036842 -0.011082   \n",
       "3    -0.423851  0.164560  0.401825  ...  0.122099  0.050478  0.119724   \n",
       "4     0.017921  0.145940 -0.016312  ...  0.012135  0.031032 -0.017324   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977 -0.058142 -0.208458 -0.120671  ...  0.004387 -0.135064  0.031170   \n",
       "5978  0.182716  0.213168  0.241474  ... -0.017176 -0.011808 -0.000613   \n",
       "5979 -0.392112  1.131950 -0.592724  ... -0.523407  0.207549 -0.355611   \n",
       "5980  0.755301 -0.127350  0.329944  ... -0.028420 -0.098941 -0.130566   \n",
       "5981 -0.882415 -0.106105 -0.051885  ...  0.065957 -0.151601  0.072650   \n",
       "\n",
       "           104       105       106       107       108       109       110  \n",
       "0    -0.050509  0.185363 -0.019726 -0.122237 -0.086713 -0.053711 -0.077012  \n",
       "1     0.116798 -0.031030 -0.049614  0.024517  0.003476  0.001157  0.006372  \n",
       "2    -0.020539 -0.010853 -0.012236 -0.003550 -0.000766  0.007166  0.015099  \n",
       "3    -0.141897 -0.014390  0.095265 -0.023132  0.142257  0.325156  0.171970  \n",
       "4    -0.006011  0.007325 -0.018732  0.004144 -0.010431 -0.004584 -0.006360  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.002395 -0.009385  0.033274  0.079296  0.230744 -0.209229 -0.247969  \n",
       "5978 -0.003491 -0.025970 -0.001241  0.008654 -0.008849 -0.015761 -0.011166  \n",
       "5979 -0.084467  0.018351  0.011924  0.144681  0.012927  0.108045 -0.044070  \n",
       "5980  0.075247 -0.050180  0.088172 -0.168739 -0.393781  0.228118  0.392946  \n",
       "5981 -0.214053 -0.182360  0.173993  0.166463  0.261078  0.370338  0.349272  \n",
       "\n",
       "[5982 rows x 112 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.436058</td>\n",
       "      <td>-0.040728</td>\n",
       "      <td>-0.376852</td>\n",
       "      <td>0.244498</td>\n",
       "      <td>-0.337669</td>\n",
       "      <td>0.594535</td>\n",
       "      <td>1.160821</td>\n",
       "      <td>-0.507886</td>\n",
       "      <td>-0.026341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371315</td>\n",
       "      <td>-0.820841</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.359050</td>\n",
       "      <td>-0.052447</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>-0.028469</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.103598</td>\n",
       "      <td>0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.495079</td>\n",
       "      <td>0.426246</td>\n",
       "      <td>0.603980</td>\n",
       "      <td>0.267780</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>-0.341812</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>-0.268278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027723</td>\n",
       "      <td>-0.408299</td>\n",
       "      <td>-0.796369</td>\n",
       "      <td>-0.191770</td>\n",
       "      <td>0.136208</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>-0.027328</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>-0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.486196</td>\n",
       "      <td>0.137751</td>\n",
       "      <td>0.094870</td>\n",
       "      <td>0.455594</td>\n",
       "      <td>0.025952</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.156926</td>\n",
       "      <td>-0.156983</td>\n",
       "      <td>-0.082030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102234</td>\n",
       "      <td>0.202870</td>\n",
       "      <td>0.137714</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>-0.046748</td>\n",
       "      <td>-0.249884</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>-0.040493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.826307</td>\n",
       "      <td>-0.968225</td>\n",
       "      <td>0.253546</td>\n",
       "      <td>0.553680</td>\n",
       "      <td>-0.338130</td>\n",
       "      <td>-0.531447</td>\n",
       "      <td>-0.663852</td>\n",
       "      <td>0.274229</td>\n",
       "      <td>0.311605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615561</td>\n",
       "      <td>0.226854</td>\n",
       "      <td>0.448593</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-0.397996</td>\n",
       "      <td>-0.505601</td>\n",
       "      <td>-0.206288</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>-0.078507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.388948</td>\n",
       "      <td>0.099101</td>\n",
       "      <td>0.054519</td>\n",
       "      <td>-0.485316</td>\n",
       "      <td>-0.493745</td>\n",
       "      <td>0.040495</td>\n",
       "      <td>0.094735</td>\n",
       "      <td>-0.274916</td>\n",
       "      <td>-0.333733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094130</td>\n",
       "      <td>0.096581</td>\n",
       "      <td>-0.122793</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>-0.033616</td>\n",
       "      <td>0.010124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.758481</td>\n",
       "      <td>0.812565</td>\n",
       "      <td>-0.108292</td>\n",
       "      <td>0.172876</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>-0.143411</td>\n",
       "      <td>0.183231</td>\n",
       "      <td>0.159825</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780837</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.534725</td>\n",
       "      <td>-0.266745</td>\n",
       "      <td>-0.442471</td>\n",
       "      <td>-0.236793</td>\n",
       "      <td>-0.081901</td>\n",
       "      <td>0.159949</td>\n",
       "      <td>-0.030645</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.564872</td>\n",
       "      <td>0.227113</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>0.254983</td>\n",
       "      <td>-0.491875</td>\n",
       "      <td>-0.342264</td>\n",
       "      <td>0.369359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097276</td>\n",
       "      <td>-0.100308</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.034280</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>1.010739</td>\n",
       "      <td>1.482501</td>\n",
       "      <td>1.119399</td>\n",
       "      <td>0.718032</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>0.340607</td>\n",
       "      <td>-0.337983</td>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.405145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111127</td>\n",
       "      <td>0.135636</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.729023</td>\n",
       "      <td>-0.262131</td>\n",
       "      <td>0.856770</td>\n",
       "      <td>0.272822</td>\n",
       "      <td>0.424178</td>\n",
       "      <td>-0.637153</td>\n",
       "      <td>-0.439690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.907570</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.415867</td>\n",
       "      <td>-0.849732</td>\n",
       "      <td>0.382268</td>\n",
       "      <td>-0.345673</td>\n",
       "      <td>0.521682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653179</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>-0.030792</td>\n",
       "      <td>-0.207601</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.046550</td>\n",
       "      <td>-0.100628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.916461</td>\n",
       "      <td>-0.791022</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.219709</td>\n",
       "      <td>-0.125223</td>\n",
       "      <td>0.073441</td>\n",
       "      <td>-0.344049</td>\n",
       "      <td>0.796474</td>\n",
       "      <td>-0.018890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057549</td>\n",
       "      <td>-0.350444</td>\n",
       "      <td>-0.070858</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>-0.310068</td>\n",
       "      <td>-0.501102</td>\n",
       "      <td>0.272890</td>\n",
       "      <td>0.247785</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.436058 -0.040728 -0.376852  0.244498 -0.337669  0.594535   \n",
       "1           1 -1.495079  0.426246  0.603980  0.267780  0.167863 -0.341812   \n",
       "2           2 -1.486196  0.137751  0.094870  0.455594  0.025952  0.268160   \n",
       "3           3  0.826307 -0.968225  0.253546  0.553680 -0.338130 -0.531447   \n",
       "4           4 -1.388948  0.099101  0.054519 -0.485316 -0.493745  0.040495   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.758481  0.812565 -0.108292  0.172876  0.196507 -0.143411   \n",
       "5978     5978 -1.564872  0.227113  0.097719  0.005096 -0.014250  0.254983   \n",
       "5979     5979  1.010739  1.482501  1.119399  0.718032 -0.021002  0.340607   \n",
       "5980     5980 -0.907570  0.014547  0.360717  0.103525  0.415867 -0.849732   \n",
       "5981     5981 -0.916461 -0.791022  0.136646  0.219709 -0.125223  0.073441   \n",
       "\n",
       "             6         7         8  ...        26        27        28  \\\n",
       "0     1.160821 -0.507886 -0.026341  ...  0.371315 -0.820841  0.280656   \n",
       "1     0.074077  0.082130 -0.268278  ... -0.027723 -0.408299 -0.796369   \n",
       "2     0.156926 -0.156983 -0.082030  ...  0.102234  0.202870  0.137714   \n",
       "3    -0.663852  0.274229  0.311605  ... -0.615561  0.226854  0.448593   \n",
       "4     0.094735 -0.274916 -0.333733  ...  0.094130  0.096581 -0.122793   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.183231  0.159825 -0.234539  ... -0.780837 -0.074323 -0.534725   \n",
       "5978 -0.491875 -0.342264  0.369359  ... -0.097276 -0.100308  0.012817   \n",
       "5979 -0.337983  0.478843  0.405145  ...  0.111127  0.135636 -0.055767   \n",
       "5980  0.382268 -0.345673  0.521682  ... -0.653179  0.014776  0.284553   \n",
       "5981 -0.344049  0.796474 -0.018890  ... -0.057549 -0.350444 -0.070858   \n",
       "\n",
       "            29        30        31        32        33        34        35  \n",
       "0     0.359050 -0.052447  0.167750 -0.028469  0.045124  0.103598  0.014635  \n",
       "1    -0.191770  0.136208  0.175161 -0.027328  0.023678  0.019509 -0.013586  \n",
       "2     0.092741 -0.046748 -0.249884  0.133006  0.062282 -0.045456 -0.040493  \n",
       "3     0.001418 -0.397996 -0.505601 -0.206288 -0.023323 -0.058132 -0.078507  \n",
       "4     0.078391 -0.059339 -0.210875  0.119112  0.095087 -0.033616  0.010124  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.266745 -0.442471 -0.236793 -0.081901  0.159949 -0.030645  0.010190  \n",
       "5978  0.030391  0.023927  0.100438 -0.032773 -0.034280 -0.015645  0.006128  \n",
       "5979 -0.729023 -0.262131  0.856770  0.272822  0.424178 -0.637153 -0.439690  \n",
       "5980 -0.030792 -0.207601 -0.053542 -0.043660 -0.118073 -0.046550 -0.100628  \n",
       "5981  0.011655 -0.310068 -0.501102  0.272890  0.247785 -0.007448  0.010920  \n",
       "\n",
       "[5982 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_nm = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_nm = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_mclas = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_mclas = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "### 중분류 구매건수 nm과 대분류 구매건수 mclas를 합친다\n",
    "\n",
    "X_train = pd.concat([X_train_nm, X_train_mclas], axis=1)\n",
    "X_test = pd.concat([X_test_nm, X_test_mclas], axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:16,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146146093967195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:08<00:12,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104661871003615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:12<00:08,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7159351542952459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:17<00:04,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134243814289685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7213215874339727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 중분류 구매건수 & 대분류 구매여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.625380</td>\n",
       "      <td>0.034396</td>\n",
       "      <td>-0.672246</td>\n",
       "      <td>0.441779</td>\n",
       "      <td>0.159294</td>\n",
       "      <td>-0.598718</td>\n",
       "      <td>0.325886</td>\n",
       "      <td>-0.936302</td>\n",
       "      <td>0.305429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143142</td>\n",
       "      <td>0.118564</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>0.089901</td>\n",
       "      <td>-0.111054</td>\n",
       "      <td>-0.021497</td>\n",
       "      <td>0.140365</td>\n",
       "      <td>0.117912</td>\n",
       "      <td>-0.126485</td>\n",
       "      <td>0.046712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.107635</td>\n",
       "      <td>-0.008147</td>\n",
       "      <td>-0.036582</td>\n",
       "      <td>-0.227227</td>\n",
       "      <td>-0.173067</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.073846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>-0.018014</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>0.015114</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.073120</td>\n",
       "      <td>-0.051948</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>-0.007939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.099033</td>\n",
       "      <td>-0.109059</td>\n",
       "      <td>-0.020829</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>-0.059710</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.179059</td>\n",
       "      <td>-0.068382</td>\n",
       "      <td>0.062943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.035945</td>\n",
       "      <td>-0.017813</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>-0.036238</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.038809</td>\n",
       "      <td>0.046284</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.014445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.265591</td>\n",
       "      <td>-0.619277</td>\n",
       "      <td>-0.279149</td>\n",
       "      <td>-0.187955</td>\n",
       "      <td>0.023135</td>\n",
       "      <td>-0.135279</td>\n",
       "      <td>-0.067050</td>\n",
       "      <td>0.675716</td>\n",
       "      <td>-0.159730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131376</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>-0.118500</td>\n",
       "      <td>0.066814</td>\n",
       "      <td>-0.149491</td>\n",
       "      <td>-0.003301</td>\n",
       "      <td>0.486243</td>\n",
       "      <td>-0.482798</td>\n",
       "      <td>-0.028555</td>\n",
       "      <td>-0.156546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.141518</td>\n",
       "      <td>-0.191579</td>\n",
       "      <td>0.005533</td>\n",
       "      <td>-0.059629</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>-0.095080</td>\n",
       "      <td>0.043151</td>\n",
       "      <td>-0.057431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.004029</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>-0.005974</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>-0.002152</td>\n",
       "      <td>0.008844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.877498</td>\n",
       "      <td>0.236507</td>\n",
       "      <td>-0.127787</td>\n",
       "      <td>-0.066931</td>\n",
       "      <td>-0.135133</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.136196</td>\n",
       "      <td>-0.051518</td>\n",
       "      <td>-0.006189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100014</td>\n",
       "      <td>-0.477439</td>\n",
       "      <td>-0.028659</td>\n",
       "      <td>0.204758</td>\n",
       "      <td>-0.015639</td>\n",
       "      <td>0.083038</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.005576</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>0.081172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.162111</td>\n",
       "      <td>-0.159106</td>\n",
       "      <td>0.019576</td>\n",
       "      <td>0.078777</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>-0.007421</td>\n",
       "      <td>-0.020261</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>-0.021468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>-0.050464</td>\n",
       "      <td>-0.032066</td>\n",
       "      <td>-0.036101</td>\n",
       "      <td>-0.007855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.199450</td>\n",
       "      <td>1.781264</td>\n",
       "      <td>-0.540263</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>0.331206</td>\n",
       "      <td>1.250888</td>\n",
       "      <td>0.351207</td>\n",
       "      <td>-0.141133</td>\n",
       "      <td>-0.117322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100453</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>-0.128008</td>\n",
       "      <td>0.088439</td>\n",
       "      <td>-0.112445</td>\n",
       "      <td>-0.079405</td>\n",
       "      <td>0.109667</td>\n",
       "      <td>0.038992</td>\n",
       "      <td>-0.088774</td>\n",
       "      <td>0.054421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.635700</td>\n",
       "      <td>-0.227858</td>\n",
       "      <td>-0.237216</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>-0.166560</td>\n",
       "      <td>-0.074526</td>\n",
       "      <td>0.129139</td>\n",
       "      <td>-0.274902</td>\n",
       "      <td>-0.380003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285796</td>\n",
       "      <td>0.651523</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>-0.241631</td>\n",
       "      <td>0.065565</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>-0.040256</td>\n",
       "      <td>-0.085648</td>\n",
       "      <td>-0.044685</td>\n",
       "      <td>-0.053650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.674396</td>\n",
       "      <td>-0.398007</td>\n",
       "      <td>0.607995</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>-0.024185</td>\n",
       "      <td>0.051853</td>\n",
       "      <td>0.060919</td>\n",
       "      <td>0.352332</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256775</td>\n",
       "      <td>0.148656</td>\n",
       "      <td>-0.043532</td>\n",
       "      <td>-0.055591</td>\n",
       "      <td>-0.132109</td>\n",
       "      <td>-0.018838</td>\n",
       "      <td>0.036651</td>\n",
       "      <td>0.041369</td>\n",
       "      <td>0.035976</td>\n",
       "      <td>-0.103166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.625380  0.034396 -0.672246  0.441779  0.159294 -0.598718   \n",
       "1           1 -1.107635 -0.008147 -0.036582 -0.227227 -0.173067  0.257546   \n",
       "2           2 -1.099033 -0.109059 -0.020829  0.007957 -0.059710  0.090729   \n",
       "3           3  0.265591 -0.619277 -0.279149 -0.187955  0.023135 -0.135279   \n",
       "4           4 -1.141518 -0.191579  0.005533 -0.059629  0.026487  0.013643   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.877498  0.236507 -0.127787 -0.066931 -0.135133  0.047662   \n",
       "5978     5978 -1.162111 -0.159106  0.019576  0.078777  0.026611 -0.007421   \n",
       "5979     5979  0.199450  1.781264 -0.540263  0.071173  0.331206  1.250888   \n",
       "5980     5980 -0.635700 -0.227858 -0.237216  0.009492 -0.166560 -0.074526   \n",
       "5981     5981 -0.674396 -0.398007  0.607995 -0.003883 -0.024185  0.051853   \n",
       "\n",
       "             6         7         8  ...       100       101       102  \\\n",
       "0     0.325886 -0.936302  0.305429  ... -0.143142  0.118564 -0.002334   \n",
       "1     0.036107 -0.059078 -0.073846  ...  0.030561 -0.018014  0.032755   \n",
       "2     0.179059 -0.068382  0.062943  ...  0.002262  0.035945 -0.017813   \n",
       "3    -0.067050  0.675716 -0.159730  ...  0.131376  0.064030 -0.118500   \n",
       "4    -0.095080  0.043151 -0.057431  ...  0.008822  0.004029  0.004533   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.136196 -0.051518 -0.006189  ...  0.100014 -0.477439 -0.028659   \n",
       "5978 -0.020261  0.025530 -0.021468  ...  0.005455  0.005500  0.013200   \n",
       "5979  0.351207 -0.141133 -0.117322  ...  0.100453  0.028486 -0.128008   \n",
       "5980  0.129139 -0.274902 -0.380003  ... -0.285796  0.651523  0.113559   \n",
       "5981  0.060919  0.352332  0.488067  ...  0.256775  0.148656 -0.043532   \n",
       "\n",
       "           103       104       105       106       107       108       109  \n",
       "0     0.089901 -0.111054 -0.021497  0.140365  0.117912 -0.126485  0.046712  \n",
       "1     0.015114  0.011464 -0.002095 -0.073120 -0.051948  0.005610 -0.007939  \n",
       "2    -0.008323 -0.036238  0.021623  0.038809  0.046284  0.007039  0.014445  \n",
       "3     0.066814 -0.149491 -0.003301  0.486243 -0.482798 -0.028555 -0.156546  \n",
       "4    -0.000862 -0.005974 -0.006765  0.007707  0.013415 -0.002152  0.008844  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.204758 -0.015639  0.083038  0.010453 -0.005576 -0.006840  0.081172  \n",
       "5978  0.006884  0.011396  0.006313 -0.050464 -0.032066 -0.036101 -0.007855  \n",
       "5979  0.088439 -0.112445 -0.079405  0.109667  0.038992 -0.088774  0.054421  \n",
       "5980 -0.241631  0.065565  0.000818 -0.040256 -0.085648 -0.044685 -0.053650  \n",
       "5981 -0.055591 -0.132109 -0.018838  0.036651  0.041369  0.035976 -0.103166  \n",
       "\n",
       "[5982 rows x 111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.436058</td>\n",
       "      <td>-0.040728</td>\n",
       "      <td>-0.376852</td>\n",
       "      <td>0.244498</td>\n",
       "      <td>-0.337669</td>\n",
       "      <td>0.594535</td>\n",
       "      <td>1.160821</td>\n",
       "      <td>-0.507886</td>\n",
       "      <td>-0.026341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371315</td>\n",
       "      <td>-0.820841</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.359050</td>\n",
       "      <td>-0.052447</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>-0.028469</td>\n",
       "      <td>0.045124</td>\n",
       "      <td>0.103598</td>\n",
       "      <td>0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.495079</td>\n",
       "      <td>0.426246</td>\n",
       "      <td>0.603980</td>\n",
       "      <td>0.267780</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>-0.341812</td>\n",
       "      <td>0.074077</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>-0.268278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027723</td>\n",
       "      <td>-0.408299</td>\n",
       "      <td>-0.796369</td>\n",
       "      <td>-0.191770</td>\n",
       "      <td>0.136208</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>-0.027328</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>-0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.486196</td>\n",
       "      <td>0.137751</td>\n",
       "      <td>0.094870</td>\n",
       "      <td>0.455594</td>\n",
       "      <td>0.025952</td>\n",
       "      <td>0.268160</td>\n",
       "      <td>0.156926</td>\n",
       "      <td>-0.156983</td>\n",
       "      <td>-0.082030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102234</td>\n",
       "      <td>0.202870</td>\n",
       "      <td>0.137714</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>-0.046748</td>\n",
       "      <td>-0.249884</td>\n",
       "      <td>0.133006</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>-0.045456</td>\n",
       "      <td>-0.040493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.826307</td>\n",
       "      <td>-0.968225</td>\n",
       "      <td>0.253546</td>\n",
       "      <td>0.553680</td>\n",
       "      <td>-0.338130</td>\n",
       "      <td>-0.531447</td>\n",
       "      <td>-0.663852</td>\n",
       "      <td>0.274229</td>\n",
       "      <td>0.311605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615561</td>\n",
       "      <td>0.226854</td>\n",
       "      <td>0.448593</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>-0.397996</td>\n",
       "      <td>-0.505601</td>\n",
       "      <td>-0.206288</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>-0.078507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.388948</td>\n",
       "      <td>0.099101</td>\n",
       "      <td>0.054519</td>\n",
       "      <td>-0.485316</td>\n",
       "      <td>-0.493745</td>\n",
       "      <td>0.040495</td>\n",
       "      <td>0.094735</td>\n",
       "      <td>-0.274916</td>\n",
       "      <td>-0.333733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094130</td>\n",
       "      <td>0.096581</td>\n",
       "      <td>-0.122793</td>\n",
       "      <td>0.078391</td>\n",
       "      <td>-0.059339</td>\n",
       "      <td>-0.210875</td>\n",
       "      <td>0.119112</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>-0.033616</td>\n",
       "      <td>0.010124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.758481</td>\n",
       "      <td>0.812565</td>\n",
       "      <td>-0.108292</td>\n",
       "      <td>0.172876</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>-0.143411</td>\n",
       "      <td>0.183231</td>\n",
       "      <td>0.159825</td>\n",
       "      <td>-0.234539</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.780837</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.534725</td>\n",
       "      <td>-0.266745</td>\n",
       "      <td>-0.442471</td>\n",
       "      <td>-0.236793</td>\n",
       "      <td>-0.081901</td>\n",
       "      <td>0.159949</td>\n",
       "      <td>-0.030645</td>\n",
       "      <td>0.010190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.564872</td>\n",
       "      <td>0.227113</td>\n",
       "      <td>0.097719</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>0.254983</td>\n",
       "      <td>-0.491875</td>\n",
       "      <td>-0.342264</td>\n",
       "      <td>0.369359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097276</td>\n",
       "      <td>-0.100308</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.023927</td>\n",
       "      <td>0.100438</td>\n",
       "      <td>-0.032773</td>\n",
       "      <td>-0.034280</td>\n",
       "      <td>-0.015645</td>\n",
       "      <td>0.006128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>1.010739</td>\n",
       "      <td>1.482501</td>\n",
       "      <td>1.119399</td>\n",
       "      <td>0.718032</td>\n",
       "      <td>-0.021002</td>\n",
       "      <td>0.340607</td>\n",
       "      <td>-0.337983</td>\n",
       "      <td>0.478843</td>\n",
       "      <td>0.405145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111127</td>\n",
       "      <td>0.135636</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.729023</td>\n",
       "      <td>-0.262131</td>\n",
       "      <td>0.856770</td>\n",
       "      <td>0.272822</td>\n",
       "      <td>0.424178</td>\n",
       "      <td>-0.637153</td>\n",
       "      <td>-0.439690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.907570</td>\n",
       "      <td>0.014547</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>0.103525</td>\n",
       "      <td>0.415867</td>\n",
       "      <td>-0.849732</td>\n",
       "      <td>0.382268</td>\n",
       "      <td>-0.345673</td>\n",
       "      <td>0.521682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.653179</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.284553</td>\n",
       "      <td>-0.030792</td>\n",
       "      <td>-0.207601</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.043660</td>\n",
       "      <td>-0.118073</td>\n",
       "      <td>-0.046550</td>\n",
       "      <td>-0.100628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.916461</td>\n",
       "      <td>-0.791022</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.219709</td>\n",
       "      <td>-0.125223</td>\n",
       "      <td>0.073441</td>\n",
       "      <td>-0.344049</td>\n",
       "      <td>0.796474</td>\n",
       "      <td>-0.018890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057549</td>\n",
       "      <td>-0.350444</td>\n",
       "      <td>-0.070858</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>-0.310068</td>\n",
       "      <td>-0.501102</td>\n",
       "      <td>0.272890</td>\n",
       "      <td>0.247785</td>\n",
       "      <td>-0.007448</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.436058 -0.040728 -0.376852  0.244498 -0.337669  0.594535   \n",
       "1           1 -1.495079  0.426246  0.603980  0.267780  0.167863 -0.341812   \n",
       "2           2 -1.486196  0.137751  0.094870  0.455594  0.025952  0.268160   \n",
       "3           3  0.826307 -0.968225  0.253546  0.553680 -0.338130 -0.531447   \n",
       "4           4 -1.388948  0.099101  0.054519 -0.485316 -0.493745  0.040495   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.758481  0.812565 -0.108292  0.172876  0.196507 -0.143411   \n",
       "5978     5978 -1.564872  0.227113  0.097719  0.005096 -0.014250  0.254983   \n",
       "5979     5979  1.010739  1.482501  1.119399  0.718032 -0.021002  0.340607   \n",
       "5980     5980 -0.907570  0.014547  0.360717  0.103525  0.415867 -0.849732   \n",
       "5981     5981 -0.916461 -0.791022  0.136646  0.219709 -0.125223  0.073441   \n",
       "\n",
       "             6         7         8  ...        26        27        28  \\\n",
       "0     1.160821 -0.507886 -0.026341  ...  0.371315 -0.820841  0.280656   \n",
       "1     0.074077  0.082130 -0.268278  ... -0.027723 -0.408299 -0.796369   \n",
       "2     0.156926 -0.156983 -0.082030  ...  0.102234  0.202870  0.137714   \n",
       "3    -0.663852  0.274229  0.311605  ... -0.615561  0.226854  0.448593   \n",
       "4     0.094735 -0.274916 -0.333733  ...  0.094130  0.096581 -0.122793   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.183231  0.159825 -0.234539  ... -0.780837 -0.074323 -0.534725   \n",
       "5978 -0.491875 -0.342264  0.369359  ... -0.097276 -0.100308  0.012817   \n",
       "5979 -0.337983  0.478843  0.405145  ...  0.111127  0.135636 -0.055767   \n",
       "5980  0.382268 -0.345673  0.521682  ... -0.653179  0.014776  0.284553   \n",
       "5981 -0.344049  0.796474 -0.018890  ... -0.057549 -0.350444 -0.070858   \n",
       "\n",
       "            29        30        31        32        33        34        35  \n",
       "0     0.359050 -0.052447  0.167750 -0.028469  0.045124  0.103598  0.014635  \n",
       "1    -0.191770  0.136208  0.175161 -0.027328  0.023678  0.019509 -0.013586  \n",
       "2     0.092741 -0.046748 -0.249884  0.133006  0.062282 -0.045456 -0.040493  \n",
       "3     0.001418 -0.397996 -0.505601 -0.206288 -0.023323 -0.058132 -0.078507  \n",
       "4     0.078391 -0.059339 -0.210875  0.119112  0.095087 -0.033616  0.010124  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.266745 -0.442471 -0.236793 -0.081901  0.159949 -0.030645  0.010190  \n",
       "5978  0.030391  0.023927  0.100438 -0.032773 -0.034280 -0.015645  0.006128  \n",
       "5979 -0.729023 -0.262131  0.856770  0.272822  0.424178 -0.637153 -0.439690  \n",
       "5980 -0.030792 -0.207601 -0.053542 -0.043660 -0.118073 -0.046550 -0.100628  \n",
       "5981  0.011655 -0.310068 -0.501102  0.272890  0.247785 -0.007448  0.010920  \n",
       "\n",
       "[5982 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_nm = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_nm = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_mclas = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_mclas = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "### 중분류 구매건수 nm과 대분류 구매건수 mclas를 합친다\n",
    "\n",
    "X_train = pd.concat([X_train_nm, X_train_mclas], axis=1)\n",
    "X_test = pd.concat([X_test_nm, X_test_mclas], axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:03<00:14,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740738810119544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:07<00:11,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190714484292466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:11<00:07,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7381672226855713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:16<00:04,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7377675840978593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:20<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7441009869335558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 대분류 구매건수 & 중분류 구매여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.031835</td>\n",
       "      <td>0.212301</td>\n",
       "      <td>-0.922307</td>\n",
       "      <td>-0.869803</td>\n",
       "      <td>-0.305008</td>\n",
       "      <td>0.092058</td>\n",
       "      <td>0.831769</td>\n",
       "      <td>-0.575745</td>\n",
       "      <td>-0.703853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102421</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>-0.375416</td>\n",
       "      <td>-0.050509</td>\n",
       "      <td>0.185363</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-0.122237</td>\n",
       "      <td>-0.086713</td>\n",
       "      <td>-0.053711</td>\n",
       "      <td>-0.077012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.545397</td>\n",
       "      <td>-0.120407</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>0.202452</td>\n",
       "      <td>0.264835</td>\n",
       "      <td>0.240070</td>\n",
       "      <td>0.129344</td>\n",
       "      <td>0.058812</td>\n",
       "      <td>0.209729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028266</td>\n",
       "      <td>0.074902</td>\n",
       "      <td>0.029886</td>\n",
       "      <td>0.116798</td>\n",
       "      <td>-0.031030</td>\n",
       "      <td>-0.049614</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.006372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.415123</td>\n",
       "      <td>-0.065534</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>-0.016653</td>\n",
       "      <td>0.142608</td>\n",
       "      <td>0.400511</td>\n",
       "      <td>-0.053878</td>\n",
       "      <td>-0.125965</td>\n",
       "      <td>-0.270389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.020539</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>-0.012236</td>\n",
       "      <td>-0.003550</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.015099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.865498</td>\n",
       "      <td>-1.222110</td>\n",
       "      <td>-0.553205</td>\n",
       "      <td>0.022980</td>\n",
       "      <td>0.309707</td>\n",
       "      <td>-0.115284</td>\n",
       "      <td>-0.423851</td>\n",
       "      <td>0.164560</td>\n",
       "      <td>0.401825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.050478</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>-0.141897</td>\n",
       "      <td>-0.014390</td>\n",
       "      <td>0.095265</td>\n",
       "      <td>-0.023132</td>\n",
       "      <td>0.142257</td>\n",
       "      <td>0.325156</td>\n",
       "      <td>0.171970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-0.078229</td>\n",
       "      <td>-0.045112</td>\n",
       "      <td>0.219325</td>\n",
       "      <td>-0.030194</td>\n",
       "      <td>-0.500378</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.145940</td>\n",
       "      <td>-0.016312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>0.031032</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>-0.006011</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>-0.018732</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>-0.004584</td>\n",
       "      <td>-0.006360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-1.161452</td>\n",
       "      <td>0.308622</td>\n",
       "      <td>-0.139144</td>\n",
       "      <td>-0.117040</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>-0.058142</td>\n",
       "      <td>-0.208458</td>\n",
       "      <td>-0.120671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>-0.135064</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>0.033274</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>0.230744</td>\n",
       "      <td>-0.209229</td>\n",
       "      <td>-0.247969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.547982</td>\n",
       "      <td>-0.166368</td>\n",
       "      <td>0.062790</td>\n",
       "      <td>-0.058637</td>\n",
       "      <td>-0.039730</td>\n",
       "      <td>0.145217</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.213168</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017176</td>\n",
       "      <td>-0.011808</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.003491</td>\n",
       "      <td>-0.025970</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>-0.008849</td>\n",
       "      <td>-0.015761</td>\n",
       "      <td>-0.011166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.204833</td>\n",
       "      <td>1.663809</td>\n",
       "      <td>-0.728419</td>\n",
       "      <td>0.605944</td>\n",
       "      <td>0.811258</td>\n",
       "      <td>1.091609</td>\n",
       "      <td>-0.392112</td>\n",
       "      <td>1.131950</td>\n",
       "      <td>-0.592724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523407</td>\n",
       "      <td>0.207549</td>\n",
       "      <td>-0.355611</td>\n",
       "      <td>-0.084467</td>\n",
       "      <td>0.018351</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.108045</td>\n",
       "      <td>-0.044070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.925491</td>\n",
       "      <td>-0.298534</td>\n",
       "      <td>-0.188338</td>\n",
       "      <td>-0.024190</td>\n",
       "      <td>0.231828</td>\n",
       "      <td>0.287504</td>\n",
       "      <td>0.755301</td>\n",
       "      <td>-0.127350</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028420</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>-0.130566</td>\n",
       "      <td>0.075247</td>\n",
       "      <td>-0.050180</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>-0.168739</td>\n",
       "      <td>-0.393781</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.392946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.512350</td>\n",
       "      <td>-0.620099</td>\n",
       "      <td>0.938312</td>\n",
       "      <td>-0.100132</td>\n",
       "      <td>-0.191828</td>\n",
       "      <td>0.116272</td>\n",
       "      <td>-0.882415</td>\n",
       "      <td>-0.106105</td>\n",
       "      <td>-0.051885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>-0.151601</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>-0.214053</td>\n",
       "      <td>-0.182360</td>\n",
       "      <td>0.173993</td>\n",
       "      <td>0.166463</td>\n",
       "      <td>0.261078</td>\n",
       "      <td>0.370338</td>\n",
       "      <td>0.349272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  1.031835  0.212301 -0.922307 -0.869803 -0.305008  0.092058   \n",
       "1           1 -1.545397 -0.120407  0.028675  0.202452  0.264835  0.240070   \n",
       "2           2 -1.415123 -0.065534  0.005330 -0.016653  0.142608  0.400511   \n",
       "3           3  0.865498 -1.222110 -0.553205  0.022980  0.309707 -0.115284   \n",
       "4           4 -1.341069 -0.078229 -0.045112  0.219325 -0.030194 -0.500378   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -1.161452  0.308622 -0.139144 -0.117040  0.072620  0.152300   \n",
       "5978     5978 -1.547982 -0.166368  0.062790 -0.058637 -0.039730  0.145217   \n",
       "5979     5979  0.204833  1.663809 -0.728419  0.605944  0.811258  1.091609   \n",
       "5980     5980 -0.925491 -0.298534 -0.188338 -0.024190  0.231828  0.287504   \n",
       "5981     5981 -0.512350 -0.620099  0.938312 -0.100132 -0.191828  0.116272   \n",
       "\n",
       "             6         7         8  ...       101       102       103  \\\n",
       "0     0.831769 -0.575745 -0.703853  ...  0.102421 -0.318619 -0.375416   \n",
       "1     0.129344  0.058812  0.209729  ...  0.028266  0.074902  0.029886   \n",
       "2    -0.053878 -0.125965 -0.270389  ...  0.018800  0.036842 -0.011082   \n",
       "3    -0.423851  0.164560  0.401825  ...  0.122099  0.050478  0.119724   \n",
       "4     0.017921  0.145940 -0.016312  ...  0.012135  0.031032 -0.017324   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977 -0.058142 -0.208458 -0.120671  ...  0.004387 -0.135064  0.031170   \n",
       "5978  0.182716  0.213168  0.241474  ... -0.017176 -0.011808 -0.000613   \n",
       "5979 -0.392112  1.131950 -0.592724  ... -0.523407  0.207549 -0.355611   \n",
       "5980  0.755301 -0.127350  0.329944  ... -0.028420 -0.098941 -0.130566   \n",
       "5981 -0.882415 -0.106105 -0.051885  ...  0.065957 -0.151601  0.072650   \n",
       "\n",
       "           104       105       106       107       108       109       110  \n",
       "0    -0.050509  0.185363 -0.019726 -0.122237 -0.086713 -0.053711 -0.077012  \n",
       "1     0.116798 -0.031030 -0.049614  0.024517  0.003476  0.001157  0.006372  \n",
       "2    -0.020539 -0.010853 -0.012236 -0.003550 -0.000766  0.007166  0.015099  \n",
       "3    -0.141897 -0.014390  0.095265 -0.023132  0.142257  0.325156  0.171970  \n",
       "4    -0.006011  0.007325 -0.018732  0.004144 -0.010431 -0.004584 -0.006360  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977 -0.002395 -0.009385  0.033274  0.079296  0.230744 -0.209229 -0.247969  \n",
       "5978 -0.003491 -0.025970 -0.001241  0.008654 -0.008849 -0.015761 -0.011166  \n",
       "5979 -0.084467  0.018351  0.011924  0.144681  0.012927  0.108045 -0.044070  \n",
       "5980  0.075247 -0.050180  0.088172 -0.168739 -0.393781  0.228118  0.392946  \n",
       "5981 -0.214053 -0.182360  0.173993  0.166463  0.261078  0.370338  0.349272  \n",
       "\n",
       "[5982 rows x 112 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.808812</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>-0.382530</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>-1.067826</td>\n",
       "      <td>0.097073</td>\n",
       "      <td>0.064659</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278258</td>\n",
       "      <td>-0.198159</td>\n",
       "      <td>-0.226099</td>\n",
       "      <td>-0.038080</td>\n",
       "      <td>0.324296</td>\n",
       "      <td>-0.434571</td>\n",
       "      <td>-0.308631</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>0.194200</td>\n",
       "      <td>-0.018975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.942326</td>\n",
       "      <td>0.181016</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.224548</td>\n",
       "      <td>0.165447</td>\n",
       "      <td>0.185474</td>\n",
       "      <td>0.260437</td>\n",
       "      <td>0.067577</td>\n",
       "      <td>-0.233817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035076</td>\n",
       "      <td>-0.147834</td>\n",
       "      <td>0.062239</td>\n",
       "      <td>0.060819</td>\n",
       "      <td>-0.054463</td>\n",
       "      <td>-0.387346</td>\n",
       "      <td>0.112056</td>\n",
       "      <td>-0.059185</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>-0.030976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.939487</td>\n",
       "      <td>0.072728</td>\n",
       "      <td>-0.171136</td>\n",
       "      <td>0.257513</td>\n",
       "      <td>-0.163384</td>\n",
       "      <td>-0.015842</td>\n",
       "      <td>-0.109646</td>\n",
       "      <td>0.098185</td>\n",
       "      <td>-0.189282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.047966</td>\n",
       "      <td>-0.038936</td>\n",
       "      <td>-0.112071</td>\n",
       "      <td>-0.006490</td>\n",
       "      <td>0.062245</td>\n",
       "      <td>-0.004990</td>\n",
       "      <td>0.035366</td>\n",
       "      <td>0.044459</td>\n",
       "      <td>0.039179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>-0.540114</td>\n",
       "      <td>-0.095850</td>\n",
       "      <td>0.039596</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.377580</td>\n",
       "      <td>0.169790</td>\n",
       "      <td>-0.019942</td>\n",
       "      <td>0.183439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>-0.014416</td>\n",
       "      <td>-0.061704</td>\n",
       "      <td>0.120444</td>\n",
       "      <td>-0.374014</td>\n",
       "      <td>0.177117</td>\n",
       "      <td>-0.243579</td>\n",
       "      <td>0.075744</td>\n",
       "      <td>-0.142311</td>\n",
       "      <td>-0.229687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.006475</td>\n",
       "      <td>-0.015659</td>\n",
       "      <td>0.083409</td>\n",
       "      <td>-0.036429</td>\n",
       "      <td>0.082568</td>\n",
       "      <td>-0.020770</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>-0.029358</td>\n",
       "      <td>0.030033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.040425</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.042274</td>\n",
       "      <td>0.049531</td>\n",
       "      <td>-0.034650</td>\n",
       "      <td>-0.017044</td>\n",
       "      <td>-0.018064</td>\n",
       "      <td>0.021210</td>\n",
       "      <td>-0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5977</th>\n",
       "      <td>5977</td>\n",
       "      <td>-0.527805</td>\n",
       "      <td>0.460797</td>\n",
       "      <td>-0.064967</td>\n",
       "      <td>-0.029257</td>\n",
       "      <td>0.232430</td>\n",
       "      <td>-0.141500</td>\n",
       "      <td>0.104384</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>-0.706434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.477599</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.023805</td>\n",
       "      <td>0.367133</td>\n",
       "      <td>0.026163</td>\n",
       "      <td>0.424302</td>\n",
       "      <td>-0.089105</td>\n",
       "      <td>-0.048746</td>\n",
       "      <td>0.062714</td>\n",
       "      <td>-0.055811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5978</th>\n",
       "      <td>5978</td>\n",
       "      <td>-1.038196</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>-0.003908</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.030509</td>\n",
       "      <td>-0.068062</td>\n",
       "      <td>-0.030968</td>\n",
       "      <td>0.011029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106910</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.158339</td>\n",
       "      <td>-0.014808</td>\n",
       "      <td>-0.045128</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>-0.058065</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>-0.046763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>5979</td>\n",
       "      <td>0.672151</td>\n",
       "      <td>1.288926</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.442555</td>\n",
       "      <td>-0.225962</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>-0.542938</td>\n",
       "      <td>-0.306575</td>\n",
       "      <td>-0.724191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267473</td>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.246498</td>\n",
       "      <td>-0.123809</td>\n",
       "      <td>-0.203993</td>\n",
       "      <td>-0.005225</td>\n",
       "      <td>-0.029028</td>\n",
       "      <td>0.124641</td>\n",
       "      <td>0.155520</td>\n",
       "      <td>0.100988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>5980</td>\n",
       "      <td>-0.561052</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>-0.023670</td>\n",
       "      <td>0.353346</td>\n",
       "      <td>0.424770</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149904</td>\n",
       "      <td>-0.020741</td>\n",
       "      <td>-0.158265</td>\n",
       "      <td>0.161862</td>\n",
       "      <td>-0.201403</td>\n",
       "      <td>-0.103223</td>\n",
       "      <td>-0.567873</td>\n",
       "      <td>-0.410687</td>\n",
       "      <td>-0.080075</td>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>5981</td>\n",
       "      <td>-0.804268</td>\n",
       "      <td>-0.300905</td>\n",
       "      <td>-0.010156</td>\n",
       "      <td>0.041940</td>\n",
       "      <td>0.061396</td>\n",
       "      <td>0.123361</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.017363</td>\n",
       "      <td>-0.044154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064577</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>-0.091283</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.027214</td>\n",
       "      <td>-0.019029</td>\n",
       "      <td>0.156810</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.190463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5982 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id         0         1         2         3         4         5  \\\n",
       "0           0  0.808812  0.047621 -0.382530  0.136842  0.068270 -1.067826   \n",
       "1           1 -0.942326  0.181016  0.039485  0.224548  0.165447  0.185474   \n",
       "2           2 -0.939487  0.072728 -0.171136  0.257513 -0.163384 -0.015842   \n",
       "3           3  0.176414 -0.540114 -0.095850  0.039596  0.054163  0.377580   \n",
       "4           4 -1.006475 -0.015659  0.083409 -0.036429  0.082568 -0.020770   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "5977     5977 -0.527805  0.460797 -0.064967 -0.029257  0.232430 -0.141500   \n",
       "5978     5978 -1.038196  0.022598  0.023371 -0.003908  0.008111  0.030509   \n",
       "5979     5979  0.672151  1.288926  0.047105  0.442555 -0.225962  0.620944   \n",
       "5980     5980 -0.561052 -0.015907  0.100263  0.082922 -0.023670  0.353346   \n",
       "5981     5981 -0.804268 -0.300905 -0.010156  0.041940  0.061396  0.123361   \n",
       "\n",
       "             6         7         8  ...        25        26        27  \\\n",
       "0     0.097073  0.064659  0.123847  ...  0.278258 -0.198159 -0.226099   \n",
       "1     0.260437  0.067577 -0.233817  ... -0.035076 -0.147834  0.062239   \n",
       "2    -0.109646  0.098185 -0.189282  ...  0.057341  0.047966 -0.038936   \n",
       "3     0.169790 -0.019942  0.183439  ...  0.156863 -0.014416 -0.061704   \n",
       "4     0.012661 -0.029358  0.030033  ...  0.008659  0.040425 -0.007492   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5977  0.104384  0.065651 -0.706434  ... -0.477599  0.215720  0.023805   \n",
       "5978 -0.068062 -0.030968  0.011029  ...  0.106910  0.017061  0.158339   \n",
       "5979 -0.542938 -0.306575 -0.724191  ... -0.267473  0.172990  0.246498   \n",
       "5980  0.424770 -0.039177  0.215357  ...  0.149904 -0.020741 -0.158265   \n",
       "5981 -0.009046 -0.017363 -0.044154  ... -0.064577  0.030567 -0.091283   \n",
       "\n",
       "            28        29        30        31        32        33        34  \n",
       "0    -0.038080  0.324296 -0.434571 -0.308631 -0.016363  0.194200 -0.018975  \n",
       "1     0.060819 -0.054463 -0.387346  0.112056 -0.059185  0.006323 -0.030976  \n",
       "2    -0.112071 -0.006490  0.062245 -0.004990  0.035366  0.044459  0.039179  \n",
       "3     0.120444 -0.374014  0.177117 -0.243579  0.075744 -0.142311 -0.229687  \n",
       "4     0.042274  0.049531 -0.034650 -0.017044 -0.018064  0.021210 -0.000362  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5977  0.367133  0.026163  0.424302 -0.089105 -0.048746  0.062714 -0.055811  \n",
       "5978 -0.014808 -0.045128  0.014905 -0.012643 -0.058065  0.033216 -0.046763  \n",
       "5979 -0.123809 -0.203993 -0.005225 -0.029028  0.124641  0.155520  0.100988  \n",
       "5980  0.161862 -0.201403 -0.103223 -0.567873 -0.410687 -0.080075  0.002968  \n",
       "5981  0.040444  0.000616 -0.027214 -0.019029  0.156810  0.123323  0.190463  \n",
       "\n",
       "[5982 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                           aggfunc=lambda x: np.where(len(x) >=1, 1, 0), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_nm = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_nm = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv('X_train.csv', encoding='cp949')\n",
    "df_test = pd.read_csv('X_test.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "IDtest = df_test.cust_id.unique()\n",
    "\n",
    "\n",
    "level = 'gds_grp_mclas_nm'\n",
    "\n",
    "train_test = pd.pivot_table(pd.concat([df_train, df_test]), index='cust_id', columns=level, values='amount',\n",
    "                            aggfunc=lambda x: len(x), fill_value=0).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# 이상치(outlier)를 제거한다.\n",
    "train_test.iloc[:,1:] = train_test.iloc[:,1:].apply(lambda x: x.clip(x.quantile(.05), x.quantile(.95)), axis=0)\n",
    "\n",
    "# 왼쪽으로 치우진 분포를 정규분포로 바꾸기 위해 로그 변환을 수행한다. -> 0.769\n",
    "train_test.iloc[:,1:] = np.log1p(train_test.iloc[:,1:])\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "mmscaler = MinMaxScaler()\n",
    "train_test.iloc[:, 1:] = mmscaler.fit_transform(train_test.iloc[:,1:])\n",
    "\n",
    "# 특성 차원이 너무 많을 경우 과적합이 발생하기 때문에 차원 축소를 실행한다.\n",
    "max_d = num_d = train_test.shape[1] - 1\n",
    "pca = PCA(n_components=max_d, random_state=0).fit(train_test.iloc[:,1:])\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_) #분산의 설명량을 누적합\n",
    "num_d = np.argmax(cumsum >= 0.99) + 1             # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "if num_d == 1: num_d = max_d\n",
    "pca = PCA(n_components=num_d, random_state=0).fit_transform(train_test.iloc[:,1:])\n",
    "train_test = pd.concat([train_test.iloc[:,0], pd.DataFrame(pca)], axis=1)\n",
    "display(train_test)\n",
    "\n",
    "# 전처리 후 학습용과 제출용 데이터로 분리한다.\n",
    "X_train_mclas = train_test.query('cust_id not in @IDtest').drop('cust_id', axis=1)\n",
    "X_test_mclas = train_test.query('cust_id in @IDtest').drop('cust_id', axis=1)\n",
    "\n",
    "### 중분류 구매건수 nm과 대분류 구매건수 mclas를 합친다\n",
    "\n",
    "X_train = pd.concat([X_train_nm, X_train_mclas], axis=1)\n",
    "X_test = pd.concat([X_test_nm, X_test_mclas], axis=1)\n",
    "\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:04<00:19,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7271076591604115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:08<00:13,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7243666597164303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:12<00:08,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7163738879621907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:17<00:04,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7363036905754795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155702668890742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 중분류 구매건수 -> percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_case3\n",
    "\n",
    "X_train = pd.read_csv('train_numbersOfPurchase_nm_percentile.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('test_numbersOfPurchase_nm_percentile.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:05<00:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557600083402836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:10<00:15,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7643869891576313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:16<00:10,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7498957464553795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:20<00:05,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7678794829024187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7511120378092855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 중분류 구매건수 & 구매여부 -> percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_case3\n",
    "\n",
    "X_train = pd.read_csv('train_numbersOfPurchase&isPurchase_nm_percentile.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('test_numbersOfPurchase&isPurchase_nm_percentile.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:05<00:23,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759760738115096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:10<00:16,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637223728106757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:15<00:10,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7514682374200723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:20<00:05,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7574715040311369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:26<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7607815540728384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 대분류 구매건수 -> percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_case3\n",
    "\n",
    "X_train = pd.read_csv('train_numbersOfPurchase_mclas_percentile.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('test_numbersOfPurchase_mclas_percentile.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:06<00:26,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7639308798999167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:13<00:19,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7622541353906033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:19<00:13,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7606946761189882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:25<00:06,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7608206491520713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:32<00:00,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605600152905199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 대분류 구매건수 & 구매여부 -> percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_case3\n",
    "\n",
    "X_train = pd.read_csv('train_numbersOfPurchase&isPurchase_mclas_percentile.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('test_numbersOfPurchase&isPurchase_mclas_percentile.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:07<00:29,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647388448707255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:12<00:20,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7651558590492077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:17<00:12,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7621151306644427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:22<00:05,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7618762162913539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:28<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759070058381985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. BOW1 -> percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 788 BOW 피쳐(상관관계, 모든전처리, percentile 이후)\n",
    "\n",
    "X_train = pd.read_csv('X_train_after_preprocessing.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('X_test_after_preprocessing.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:05<00:21,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7380369057547957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:09<00:15,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742011572143453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:15<00:10,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751633305532388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:21<00:05,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7373896649986098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:26<00:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7427717542396443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. 중분류 W2V (EmbeddingFeaturzier + gender cosine similarity): 906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_after_percentile_nm.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('X_test_after_percentile_nm.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:15<01:02, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718324298026134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:27<00:43, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7722364122880178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:41<00:28, 14.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7674668126216291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:59<00:15, 15.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7688829232693912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:13<00:00, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7764195857659161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. 대분류 W2V (EF + gender CS): 906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_after_percentile_mclas_nm.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('X_test_after_percentile_mclas_nm.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:16<01:04, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7785437517375591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:34<00:50, 16.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7748079997219907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:48<00:32, 16.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7790780511537392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:04<00:15, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774486551292744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:28<00:00, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7773578676675007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. 중분류&대분류(EF + gender CS)1: 1206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_after_percentile_nm&mclas.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('X_test_after_percentile_nm&mclas.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:13<00:53, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7724275437864887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:26<00:39, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7800293647484015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:37<00:25, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7800423964414791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:47<00:11, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7716412983041423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:00<00:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791128023352794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. 중분류&대분류(EF + gender CS)2: 1206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_after_percentile_nm&mclas2.csv', encoding='cp949')\n",
    "X_test = pd.read_csv('X_test_after_percentile_nm&mclas2.csv', encoding='cp949')\n",
    "y_train = pd.read_csv('y_train.csv', encoding='cp949').gender\n",
    "\n",
    "i = int(round(X_train.shape[0] * 0.8, 0))\n",
    "X_valid, y_valid = X_train[i:], y_train[i:]\n",
    "X_train, y_train = X_train[:i], y_train[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 1/5 [00:15<01:03, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7675840978593272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:34<00:49, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7634182999721991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:47<00:31, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741260077842647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [01:03<00:15, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7729184042257436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:22<00:00, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307695649152071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(5)): \n",
    "# model architecture\n",
    "    model = Sequential(name = 'dnn model')\n",
    "    model.add(Dense(32, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# choose the optimizer and the cost function\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train the model -> verbose=0: silent\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)]\n",
    "\n",
    "    hist = model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
    "        batch_size=64, epochs=200, callbacks=callbacks, verbose=0)\n",
    "\n",
    "# visualize training history\n",
    "# plt.plot(hist.history['loss'], label='train loss')\n",
    "# plt.plot(hist.history['val_loss'], label='validation loss')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('Loss')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(hist.history['acc'], label='train acc')\n",
    "# plt.plot(hist.history['val_acc'], label='validation acc')\n",
    "# plt.legend()\n",
    "# plt.xlabel('epoch')\n",
    "# plt.title('acc')\n",
    "# plt.show()\n",
    "\n",
    "# evaluate the model performance\n",
    "\n",
    "#print(model.evaluate(X_test, y_test))\n",
    "#if roc_auc_score(y_test, model.predict(X_test)) >= 0.755:\n",
    "#    print(f'1층: {dr1},드롭1: {drop1},2층: {dr2}, 드롭2: {drop2}, 3층: {dr3}')\n",
    "#    print(roc_auc_score(y_test, model.predict(X_test)))\n",
    "    print(roc_auc_score(y_valid, model.predict(X_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
